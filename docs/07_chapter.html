<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Моделирование конвергентных процессов в языке и речи цифровыми методами – ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./13_references.html" rel="next">
<link href="./06_chapter.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-bcbce66894bfa8e7e94e40e0186b9bb8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-22a2acbb0f7ec22c15d721aa9f56f094.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./07_chapter.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Моделирование конвергентных процессов в языке и речи цифровыми методами</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">ОТЧЕТ О НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">СПИСОК ИСПОЛНИТЕЛЕЙ</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Квантитативные методы в исследованиях малых языков России и нестандартных разновидностей русского языка</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Логлаба придумайте название</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Формлаба придумайте название</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Лаборатория по корпусным технологиям придумайте название!</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Исследования морфосинтаксиса и семантики глагольных форм в языках Севера и Арктики</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Исследование и сравнительный анализ вариативности обозначения причинно-следственных связей в текстах обучающихся и экспертов, языковых особенностей и возможности орфокоррекции учебных текстов</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_chapter.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Моделирование конвергентных процессов в языке и речи цифровыми методами</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">СОДЕРЖАНИЕ</h2>
   
  <ul>
  <li><a href="#конвергентные-процессы-в-синтетической-и-естественной-речи" id="toc-конвергентные-процессы-в-синтетической-и-естественной-речи" class="nav-link active" data-scroll-target="#конвергентные-процессы-в-синтетической-и-естественной-речи"><span class="header-section-number">7.1</span> Конвергентные процессы в синтетической и естественной речи</a>
  <ul class="collapse">
  <li><a href="#специфика-синтетических-текстов-и-текстов-порожденных-естественно-в-разных-жанровых-условиях" id="toc-специфика-синтетических-текстов-и-текстов-порожденных-естественно-в-разных-жанровых-условиях" class="nav-link" data-scroll-target="#специфика-синтетических-текстов-и-текстов-порожденных-естественно-в-разных-жанровых-условиях"><span class="header-section-number">7.1.1</span> Специфика синтетических текстов и текстов, порожденных естественно в разных жанровых условиях</a></li>
  </ul></li>
  <li><a href="#проблемные-зоны-и-технологические-решения-в-автоматической-обработке-стандартных-и-нестандартных-речевых-данных" id="toc-проблемные-зоны-и-технологические-решения-в-автоматической-обработке-стандартных-и-нестандартных-речевых-данных" class="nav-link" data-scroll-target="#проблемные-зоны-и-технологические-решения-в-автоматической-обработке-стандартных-и-нестандартных-речевых-данных"><span class="header-section-number">7.2</span> Проблемные зоны и технологические решения в автоматической обработке стандартных и нестандартных речевых данных</a>
  <ul class="collapse">
  <li><a href="#диаризация-оценка-качества-на-материалах-корпуса-обработка-новых-данных-спонтанной-устной-речи-курс" id="toc-диаризация-оценка-качества-на-материалах-корпуса-обработка-новых-данных-спонтанной-устной-речи-курс" class="nav-link" data-scroll-target="#диаризация-оценка-качества-на-материалах-корпуса-обработка-новых-данных-спонтанной-устной-речи-курс"><span class="header-section-number">7.2.1</span> Диаризация: оценка качества на материалах корпуса, обработка новых данных спонтанной устной речи КУРС</a></li>
  <li><a href="#автоматическое-распознавание-атипичной-речи-на-русском-языке-на-материале-речи-пациентов-с-афазией-разработка-бенчмарка" id="toc-автоматическое-распознавание-атипичной-речи-на-русском-языке-на-материале-речи-пациентов-с-афазией-разработка-бенчмарка" class="nav-link" data-scroll-target="#автоматическое-распознавание-атипичной-речи-на-русском-языке-на-материале-речи-пациентов-с-афазией-разработка-бенчмарка"><span class="header-section-number">7.2.2</span> Автоматическое распознавание атипичной речи на русском языке (на материале речи пациентов с афазией) : разработка бенчмарка</a></li>
  <li><a href="#объектный-сентимент-анализ-отзывов-на-культурные-институции-с-помощью-больших-языковых-моделей-на-материале-датасета-отзывов-посетителей-владимиро-суздальского-музея-заповедника" id="toc-объектный-сентимент-анализ-отзывов-на-культурные-институции-с-помощью-больших-языковых-моделей-на-материале-датасета-отзывов-посетителей-владимиро-суздальского-музея-заповедника" class="nav-link" data-scroll-target="#объектный-сентимент-анализ-отзывов-на-культурные-институции-с-помощью-больших-языковых-моделей-на-материале-датасета-отзывов-посетителей-владимиро-суздальского-музея-заповедника"><span class="header-section-number">7.2.3</span> Объектный сентимент-анализ отзывов на культурные институции с помощью больших языковых моделей (на материале датасета отзывов посетителей Владимиро-суздальского музея-заповедника)</a></li>
  <li><a href="#конвергентные-речевые-практики-русскоязычного-сегмента-интернет-на-материале-корпусных-данных" id="toc-конвергентные-речевые-практики-русскоязычного-сегмента-интернет-на-материале-корпусных-данных" class="nav-link" data-scroll-target="#конвергентные-речевые-практики-русскоязычного-сегмента-интернет-на-материале-корпусных-данных"><span class="header-section-number">7.2.4</span> Конвергентные речевые практики русскоязычного сегмента Интернет (на материале корпусных данных)</a></li>
  </ul></li>
  <li><a href="#внедрение-результатов-исследовательской-работы-по-изучению-цифровыми-методами-конвергентных-процессов-в-современной-русской-речевой-практике" id="toc-внедрение-результатов-исследовательской-работы-по-изучению-цифровыми-методами-конвергентных-процессов-в-современной-русской-речевой-практике" class="nav-link" data-scroll-target="#внедрение-результатов-исследовательской-работы-по-изучению-цифровыми-методами-конвергентных-процессов-в-современной-русской-речевой-практике"><span class="header-section-number">7.3</span> Внедрение результатов исследовательской работы по изучению цифровыми методами конвергентных процессов в современной русской речевой практике</a>
  <ul class="collapse">
  <li><a href="#лингвистические-цифровые-ресурсы-и-прикладные-разработки" id="toc-лингвистические-цифровые-ресурсы-и-прикладные-разработки" class="nav-link" data-scroll-target="#лингвистические-цифровые-ресурсы-и-прикладные-разработки"><span class="header-section-number">7.3.1</span> Лингвистические цифровые ресурсы и прикладные разработки</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Моделирование конвергентных процессов в языке и речи цифровыми методами</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="конвергентные-процессы-в-синтетической-и-естественной-речи" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="конвергентные-процессы-в-синтетической-и-естественной-речи"><span class="header-section-number">7.1</span> Конвергентные процессы в синтетической и естественной речи</h2>
<section id="специфика-синтетических-текстов-и-текстов-порожденных-естественно-в-разных-жанровых-условиях" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="специфика-синтетических-текстов-и-текстов-порожденных-естественно-в-разных-жанровых-условиях"><span class="header-section-number">7.1.1</span> Специфика синтетических текстов и текстов, порожденных естественно в разных жанровых условиях</h3>
<section id="описание-эстетически-нагруженных-вербальных-стимулов-картин-мультимодальными-языковыми-моделями-и-информантами" class="level4" data-number="7.1.1.1">
<h4 data-number="7.1.1.1" class="anchored" data-anchor-id="описание-эстетически-нагруженных-вербальных-стимулов-картин-мультимодальными-языковыми-моделями-и-информантами"><span class="header-section-number">7.1.1.1</span> Описание эстетически нагруженных вербальных стимулов (картин) мультимодальными языковыми моделями и информантами</h4>
<p>В отчетном периоде продолжалась работа по созданию датасета описаний картин из коллекции Государственного Эрмитажа <span class="citation" data-cites="Kolmogorova2025">[<a href="13_references.html#ref-Kolmogorova2025" role="doc-biblioref">1</a>]</span>. На данный момент коллекция включает в себя описания 2000 картин из экспозиционных залов, имеющих наибольшую посещаемость: Французская живопись XIX-XX веков, Итальянская живопись XIII-XVIII веков, Английская живопись XVI-XX веков, Французская живопись XV-XVIII веков, Русская живопись XVIII – начала XX века, Фламандская живопись XVII-XVIII веков, Немецкая живопись XVI-XVIII веков, Немецкая живопись XIX-XX веков, Голландская живопись XV-XVI веков, Испанская живопись XV-XX веков, Бельгийская живопись XIX-XX веков, Живопись различных европейских школ, Иконы. Каждая картина описывалась информантами и Visual Language Model (VLM), разработанной компанией Яндекс и находящейся в закрытом доступе<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. VLM представляют собой класс мультимодальных моделей на основе технологии Transformers <span class="citation" data-cites="Lin2024">[<a href="13_references.html#ref-Lin2024" role="doc-biblioref">2</a>]</span>. VLM натренированы на задачу Image to Text: распознают изображения, а затем дают комплексное вербальное описание, сопоставляя эмбеддинги частей изображения и слов.</p>
<p>Для создания датасета мы провели эксперименты с моделью и с 100 информантами (mean age=21,2; 74 женщины, 26 мужчин, студенты вузов г.Петербурга). Информантам в удаленном асинхронном режиме предлагалась таблица, где в одной колонке располагались картины (от 76 до 100), а во второй колонке предлагалось оставить описание. Информантам предлагалась следующая инструкция: «Опишите содержание картины своими словами. Вы можете начать с таких фраз, как “На картине изображено…”. Предоставьте подробные описания, состоящие из нескольких предложений. Пожалуйста, воздержитесь от поиска дополнительной информации о произведении искусства — опишите только то, что вы видите. Если вы узнаете историческую личность, пожалуйста, укажите её». Участники работали без ограничений по времени, и в среднем на заполнение одной таблицы уходило три недели. В среднем каждый респондент описал 176 картин. Участники предоставляли письменные описания картин, вводя свои тексты в предназначенные для этого ячейки общего файла электронной таблицы, который они затем возвращали кураторам проекта. В итоге полученный набор данных достиг разного уровня охвата: для каждого произведения искусства было получено от 3 (17,5% от общей выборки), 4 (53,9%), 5 (17,4%) или 12 (11,2%) отдельных описаний от разных информантов.</p>
<p>Метаданные для каждой из картин были сохранены в виде JSON-файла, названного по уникальному идентификатору картины в базе проекта.</p>
<p>По сравнению с прошлым годом объем датасета был увеличен на 50%. Полученный датасет позволил провести ряд экспериментов.</p>
<p>Во-первых, было проведено количественное сравнение характеристик текстов описаний картин от ИИ и от информантов. Статистический анализ текстов выявил различия в их количественных характеристиках: описания от моделей характеризовались средней длиной предложения 13,4 слова (стандартное отклонение 2,23), средним числом слов в тексте 65,1 (стандартное отклонение 20,1), с минимумом 18 и максимумом 156 слов; описания от информантов — средней длиной предложения 10,3 слова (стандартное отклонение 13,9), средним числом слов 58,7 (стандартное отклонение 40,3), с минимумом 3 и максимумом 324 слова. Таким образом, описания, сгенерированные моделями, отличаются большей стабильностью объема и длины предложений, а также меньшей вариативностью, что указывает на их более унифицированный и предсказуемый характер по сравнению с человеческими текстами, демонстрирующими значительную индивидуальную разнородность.</p>
<p>Кроме того, мы выдвинули гипотезу о том, что 1) лексическое и семантическое разнообразие описаний информантов зависит от типа описываемого изображения (люди/ натурфакты/абстрактные изображения — например, информанты дают более похожие друг на друга описания изображений природы, но более разнообразные, когда нужно описать людей или абстракции); 2) тип описываемого изображения предопределяет также степень отличности описаний информантов от описаний модели (например, описания абстрактных изображений максимально отличаются у информантов и моделей, а описания монофигурных композиций — минимально).</p>
<p>Для проверки гипотез мы использовали метод векторизации текстовых описаний с помощью модели <em>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2.</em></p>
<p>Использовалась подвыборка из 1215 картин. Для каждой картины были получены по три описания от мультимодальных моделей (Qwen2-VL-7B-Instruct, Qwen2.5-VL-7B-Instruct, Gemma-3-27b-it), что в сумме составило 3 645 описаний, и по 3 описания, полученных в рамках анкетирования от 24 информантов (средний возраст – 21 год, среднее количество картин, описанных одним информантом – 176). Итоговое количество исследуемых описаний “от человека” – 4 721.</p>
<p>Картины были дополнительно размечены по шести композиционным категориям: один человек (портрет или фигура в пейзаже), два человека (взаимодействующие или нет), три человека, четыре человека и более (групповая сцена), природа или прочие объекты (пейзаж, натюрморт, архитектура без людей или с мелкими фигурами), абстракция (без узнаваемых объектов или с неидентифицируемыми формами). Количество описанных картин по категориям составило соответственно 423 (1 269 описаний), 337 (1 011), 264 (792), 112 (336), 64 (192) и 16 (48).</p>
<p>Анализ включал векторизацию описаний с помощью модели-трансформера и вычисление косинусной близости в трех парадигмах: между описаниями от информантов, между описаниями от моделей и между парами описаний от информантов и моделей. Результаты показали, что описания от моделей в целом демонстрируют большую семантическую однородность по сравнению с описаниями от информантов независимо от категории. Медианные значения косинусной близости для описаний от информантов варьировались от 0,72 (три человека и абстракция) до 0,79 (один человек), с наибольшим разбросом в категориях с большим числом фигур; для описаний от моделей — от 0,77 (два и три человека) до 0,84 (природа и прочие объекты).</p>
<p>Анализ по категориям выявил закономерности в вербализации визуальной информации VLM-моделями и информантами. Наиболее согласованными оказались описания одиночных фигур и объектов природы: модели достигали медианной близости значений косинусного расстояния между описаниями 0,83 и 0,84 соответственно, информанты — 0,79 и 0,78, а межгрупповая близость составляла 0,78. По мере увеличения числа людей на изображении семантическое разнообразие возрастало: для сцен с четырьмя и более фигурами медианная близость значений косинусного расстояния между описаниями падала до 0,73 у информантов и 0,78 у моделей, с межгрупповой близостью 0,71. Абстрактные композиции демонстрировали наименьшую межгрупповую близость 0,69, что частично объясняется малым объемом выборки, но также указывает на различия в интерпретации неконкретных форм. На <a href="#fig-spb_1" class="quarto-xref">рисунок&nbsp;<span>7.1</span></a> представлено сравнение медианных значений косинусной близости описаний по категориям картин для информантов, моделей и межгрупповой выборки.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_0.jpg" class="img-fluid figure-img" width="495">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.1 – Медианное значение косинусной близости описаний по категориям картин
</figcaption>
</figure>
</div>
</div>
</div>
<p>Исследование выявило заметные различия в том, как люди и визуально-языковые модели семантически обрабатывают изображения: модели дают более согласованные описания, а расхождения с человеческими текстами увеличиваются при усложнении сцены или переходе к абстрактным картинам.</p>
<p>В данный момент ведется исследование вербализации цвета в описаниях от информантов и от моделей. Проводится экспертная разметка описаний, которая в дальнейшем будет проанализирована на предмет различий в выражении семантики цвета. Первичные результаты указывают на то, что информанты описывают цвета в большем объеме, а также более разнообразными способами, чем модели.</p>
<p>РИД: База данных «База данных текстовых описаний и векторных представлений картин из Цифровой коллекции Государственного Эрмитажа»</p>
<p>Регистрационный номер: 2025622931</p>
<p>Вид РИД: база данных.</p>
<p>Авторский коллектив:</p>
<ul>
<li>Колмогорова Анастасия Владимировна (заведующий Лабораторией языковой конвергенции);</li>
<li>Налобина Полина Алексеевна (стажер-исследователь).</li>
</ul>
<p>Общее описание и состав:</p>
<ul>
<li>База данных представляет собой коллекцию структурированных описаний и текстовых представлений произведений искусства из собрания Государственного Эрмитажа.</li>
</ul>
<p>Состав РИД включает:</p>
<ul>
<li>Набор файлов в формате .json, содержащих официальные метаданные картин;</li>
<li>Набор файлов в формате .txt, содержащих текстовые описания, сгенерированные искусственным интеллектом и респондентами.</li>
</ul>
</section>
<section id="оценка-качества-суммаризации-художественных-текстов-большими-языковыми-моделями" class="level4" data-number="7.1.1.2">
<h4 data-number="7.1.1.2" class="anchored" data-anchor-id="оценка-качества-суммаризации-художественных-текстов-большими-языковыми-моделями"><span class="header-section-number">7.1.1.2</span> Оценка качества суммаризации художественных текстов большими языковыми моделями</h4>
<p>В отчетном периоде сотрудники лаборатории, продолжая одну из магистральных тем “Цифровые методы в изучении литературы”, начали разработку задачи оценки качества автоматической суммаризации художественных текстов русском языке. В первую очередь оценивается успешность и применимость алгоритмов суммаризации на материале Корпуса русского рассказа, также предпринимается попытка определить лексические и структурные особенности художественного текста, которые могут влиять на результат автоматической суммаризации (лексическое разнообразие, нарушение фабулы, ненадежный рассказчик, смена лица повествования, вставки флешбеков и фрагментов других жанров).</p>
<p>За основу дизайна данного исследования был взят эксперимент ученых Колумбийского университета <span class="citation" data-cites="Subbiah2024">[<a href="13_references.html#ref-Subbiah2024" role="doc-biblioref">3</a>]</span>. Эксперимент включал в себя несколько этапов:</p>
<ol type="1">
<li>Формирование сбалансированной выборки из Корпуса русского рассказа;</li>
<li>Суммаризация избранных документов;</li>
<li>Автоматическая оценка результатов моделей;</li>
<li>Экспертная оценка результатов моделей и структурной сложности исходных текстов;</li>
<li>Сравнение полученных данных и выявление особенностей, повлиявших на результат выдачи.</li>
</ol>
<p>Выборка аннотированных текстов из Корпуса русского рассказа была сбалансирована по параметру лица повествования. В результате в нее вошли 100 рассказов: 50 рассказов с повествованием от первого лица; 50 рассказов — от третьего лица.</p>
<p>Суммарный объем корпуса, взятого в работу, составил 330 129 словоупотреблений. Средняя длина рассказа — 3 301,29 (sd = 2781,14).</p>
<p>В ходе эксперимента было обработано 100 рассказов и получено 300 саммари — по 100 от каждой модели (GigaChat, T5 и sumy).</p>
<p>Нарратив в произведении — один из инструментов передачи авторской позиции, так как от расположения событий в тексте, уделенного им художественного времени, зависит их важность для рассказываемой истории. События в тексте могут располагаться не только нелинейно, но и сжиматься и растягиваться <span class="citation" data-cites="SHmid2003">[<a href="13_references.html#ref-SHmid2003" role="doc-biblioref">4</a>]</span>. Предварительная оценка результатов показала, что алгоритмы автоматической суммаризации не всегда справляются с авторской передачей времени. Кроме того, эмпирический анализ показывает, что автоматическая суммаризация не всегда справляется с обработкой произведений с ненадежным рассказчиком. Модели плохо обрабатывают неожиданные развязки, не включают их в текст пересказа и таким образом создают неправильное впечатление о тексте, упуская ключевые моменты сюжета. Так, в рассказе «В плену» речь идет о двух разведчиках, которым нужно было найти «языка». Солдаты встретили поляка Яна Балицкого, готового сбежать в русскую армию добровольно, но попали в плен, а он успел убежать. Оказалось, что поляк дошел до русской армии и стал служить им переводчиком, однако рассказчик до последнего это скрывает. Ни одна из моделей не включает в пересказ развязку, поэтому создается ошибочное впечатление о том, что один из героев — предатель.</p>
<p>В качестве основных метрик автоматической оценки результатов суммаризации были избраны классические ROUGE <span class="citation" data-cites="Lin2004">[<a href="13_references.html#ref-Lin2004" role="doc-biblioref">5</a>]</span>, BLEU <span class="citation" data-cites="Papineni2002">[<a href="13_references.html#ref-Papineni2002" role="doc-biblioref">6</a>]</span> и BERTScore <span class="citation" data-cites="Zhang2019">[<a href="13_references.html#ref-Zhang2019" role="doc-biblioref">7</a>]</span>.</p>
<p>Автоматическая оценка саммари показала, что наиболее качественные тексты создает GigaChat. Чуть менее успешной оказалась модель t5 и наименее успешно с задачей справилась модель sumy, что особенно видно по метрикам, подсчитывающим совпадающие n-граммы. Нейросетевые же метрики показали, что все модели справились с задачей сравнительно хорошо, однако абстрактивные модели – чуть лучше.</p>
<p>Стоит отметить, что все модели показали сравнительно низкие оценки ROUGE и BLEU, в то время как показатели BERTScore в целом высокие. Это говорит о том, что статистические подходы не совсем подходят для задачи суммаризации из-за отсутствия перефразирования, а большие языковые модели, напротив, подбирают синонимичные конструкции слишком вольно.</p>
<div id="tbl-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.1 – Результаты автоматической оценки работы моделей
</figcaption>
<div aria-describedby="tbl-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th>Модель</th>
<th>ROUGE-1</th>
<th>ROUGE-2</th>
<th>ROUGE-L</th>
<th>BLEU</th>
<th>BERT-Precision</th>
<th>BERT-Recall</th>
<th>BERT-F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GigaChat</td>
<td>0,3405</td>
<td>0,0693</td>
<td>0,2028</td>
<td>0,0178</td>
<td>0,6709</td>
<td>0,6864</td>
<td>0,6782</td>
</tr>
<tr class="even">
<td>Т5</td>
<td>0,3225</td>
<td>0,0612</td>
<td>0,1930</td>
<td>0,0145</td>
<td>0,6754</td>
<td>0,6771</td>
<td>0,6757</td>
</tr>
<tr class="odd">
<td>sumy</td>
<td>0,2442</td>
<td>0,0348</td>
<td>0,1432</td>
<td>0,0063</td>
<td>0,6247</td>
<td>0,6573</td>
<td>0,6400</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>В общей сложности 300 кратких содержаний от трех разных моделей прошли экспертную оценку по следующим критериям:</p>
<ul>
<li>Охват (coverage) — упоминание важных сюжетных точек, метрика оценивает смысловую составляющую;</li>
<li>Достоверность (faithfulness) — наличие несуществующих в исходном тексте деталей или искажение истории;</li>
<li>Связность (coherence) текста;</li>
<li>Анализ — наличие верной интерпретации авторской позиции или тем рассказа.</li>
</ul>
<p>По каждому из четырех пунктов эксперт выставляет оценку по шкале Лайкерта, где 1 — худший результат, а 4 — лучший. Также экспертам было предложено самостоятельно выбрать фрагменты суммаризации, где допущена ошибка и отнести ее к одному из четырех критериев, приведенных выше.</p>
<p>Из <a href="#tbl-2" class="quarto-xref">таблица&nbsp;<span>7.2</span></a> видно, что саммари, созданные человеком, несколько уступают большой языковой модели GigaChat в уодобочитаемости текста и его аналитичности, однако имеют преимущество в передаче основных моментов сюжета и высокой достоверности. Краткие содержания модели GigaChat показывают самые высокие результаты в сравнении с другими моделями, но несколько уступают эталонным суммаризациям в охвате и достоверности, что не позволяет рассматривать этот инструмент как то, что может заменить пересказ человека, однако их преимущество заключается в высокой связности генерируемого текста и включения анализа в пересказ. Тексты модели T5, несмотря на внешнюю схожесть с пересказами эталона, о чем говорят высокие показатели автоматической оценки, значительно уступают другим моделям, совершая фактические ошибки в 74 рассказах из 100. Краткие содержания экстрактивной модели sumy отличаются сравнительно высокой достоверностью, однако обладают наименьшей связностью, аналитичностью и плохо передают основные события из текста оригинала, включая в повествование незначительные детали и упуская важные моменты для понимания.</p>
<div id="tbl-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.2 – Экспертная оценка кратких содержаний
</figcaption>
<div aria-describedby="tbl-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Модель</th>
<th>Охват</th>
<th></th>
<th>Достоверность</th>
<th></th>
<th>Связность</th>
<th></th>
<th>Анализ</th>
<th></th>
<th>Итог</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>mean</td>
<td>sd</td>
<td>mean</td>
<td>sd</td>
<td>mean</td>
<td>sd</td>
<td>mean</td>
<td>sd</td>
<td>mean</td>
<td>sd</td>
</tr>
<tr class="even">
<td>GigaChat</td>
<td>3,35</td>
<td>0,66</td>
<td>3,05</td>
<td>1,01</td>
<td>3,91</td>
<td>0,35</td>
<td>2,49</td>
<td>1,14</td>
<td>12,71</td>
<td>2,40</td>
</tr>
<tr class="odd">
<td>T5</td>
<td>1,94</td>
<td>0,93</td>
<td>1,48</td>
<td>0,85</td>
<td>2,71</td>
<td>1,11</td>
<td>1,32</td>
<td>0,53</td>
<td>7,45</td>
<td>2,48</td>
</tr>
<tr class="even">
<td>Sumy</td>
<td>1,62</td>
<td>0,72</td>
<td>3,39</td>
<td>0,92</td>
<td>1,68</td>
<td>0,68</td>
<td>1,09</td>
<td>0,41</td>
<td>7,7</td>
<td>2,06</td>
</tr>
<tr class="odd">
<td>Human</td>
<td>3,55</td>
<td>0,69</td>
<td>3,69</td>
<td>0,76</td>
<td>3,73</td>
<td>0,49</td>
<td>1,75</td>
<td>1,03</td>
<td>12,72</td>
<td>1,99</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Чтобы выделить особенности художественного текста, влияющие на результат суммаризации, были рассмотрены такие показатели как коэффициент лексического многообразия, нарушение фабулы, наличие ненадежного рассказчика в тексте, смена лица повествователя (грамматическая и смысловая), включение флэшбеков и повествования о снах, а также вставка фрагментов других жанров — песен, стихотворений, анекдотов и др. Корреляционный анализ проводился путем подсчета коэффициента корреляции Пирсона.</p>
<p>Оценка структурной сложности рассказа складывается из пяти критериев и составляет от 0 до 5 баллов. Эксперты оценивали текст с опорой на 5 критериев. По каждому из критериев текст мог получить оценку 1 или 0. Так, в общей сложности нарративная структура произведения оценивалась максимум в 5 баллов и минимум в 0, где 5 — наиболее усложненное повествование, 0 — наиболее простое. В <a href="#tbl-3" class="quarto-xref">таблица&nbsp;<span>7.3</span></a> представлены результаты экспертной разметки структры рассказов на нарративную сложность.</p>
<div id="tbl-3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.3 – Оценка нарративной сложности текстов
</figcaption>
<div aria-describedby="tbl-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Критерии</th>
<th>К1. Фабула</th>
<th>К2. Рассказчик</th>
<th>К3. Лицо</th>
<th>К4. Флешбеки</th>
<th>К5. Вставки других жанров</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Кол-во рассказов</td>
<td>51</td>
<td>38</td>
<td>16</td>
<td>53</td>
<td>18</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Корреляционный анализ позволяет сделать следующие выводы:</p>
<ul>
<li>TTR: повышение коэффициента TTR скорее положительно влияет на лексическую схожесть текстов модели и эталона в случае генеративных моделей (T5, GigaChat), однако несколько отрицательно — в случае экстрактивной модели (sumy). На передачу основной информации текста коэффициент TTR влияет положительно для модели T5, несколько улучшает качество текстов экстрактивной суммаризации и практически не имеет связи с результатом большой языковой модели GigaChat;</li>
<li>Лицо повествования (грамматический показатель): параметр практически не влияет на результат суммаризации, однако гипотеза о том, что перволичное повествование будет несколько затруднять пересказ модели частично подтвердилась, но только относительно лексической схожести сгенерированного и эталонного текстов. На содержательные качества саммари, такие как фактическая точность, полнота передачи сюжета, связность и наличие анализа перволичное повествование не влияет в случае модели GigaChat и слабо положительно влияет относительно моделей T5 и sumy;</li>
<li>Нарушение фабулы: нелинейное повествование слабо негативно влияет на качество суммаризации GigaChat, T5, особенно на фактическую точность текстов, но влияет слабо положительно на достоверность и логическую связность экстрактивной модели sumy. Этот параметр не влияет на лексическую схожесть текстов саммари и эталона;</li>
<li>Ненадежный рассказчик: этот параметр коррелирует с перволичным повествованием, так как одним из критериев определения ненадежного рассказчика является первое лицо повествования. В целом ненадежный рассказчик практически не влияет на результат модели GigaChat, однако несколько негативно влияет на лексическую схожесть саммари и эталона и связность предложений (r = -0,16; r = -0,16). Этот параметр, как и первое лицо, негативно влияет на лексическую схожесть саммари T5 (r = -0,14), в особенности sumy и эталона (r = -0,19), однако скорее положительно влияет на полноту передачи основной информации, связность текста и анализ в текстах этих моделей;</li>
<li>Смена лица рассказчика или повествования: этот параметр практически не влияет на результат работы моделей, однако имеет слабую отрицательную связь с автоматическими и экспертными оценками генеративных моделей GigaChat и T5;</li>
<li>Флешбеки: повествования о прошлом практически не влияют на результаты абстрактивных моделей GigaChat и T5, однако если и влияют, то скорее слабо негативно. В то время как для экстрактивной суммаризации вставки флешбеков, напротив, являются положительным параметром, хорошо влияющим на фактическую точность текста;</li>
<li>Вставки других жанров: наличие в тексте фрагментов других жанров практически не влияет на результат работы большой языковой модели, однако слабо негативно влияет на лексическую схожесть текстов T5, sumy с текстами эталона и слабо положительно — на полноту передачи основных событий текста и связность краткого содержания модели sumy.</li>
</ul>
<p>Таким образом, получены данные о том, что существующие алгоритмы автоматической суммаризации не всегда справляются с задачей краткого пересказа художественного текста. Расхождения во влиянии разных параметров на результат суммаризации указывают на то, что они влияют на результат не так сильно, как обучающая выборка каждой конкретной модели. В перспективе исследования разработка нового инструмента суммаризации путем тонкой настройки моделей с использованием улучшенных версий эталонных кратких содержаний в качестве обучающей выборки.</p>
</section>
</section>
</section>
<section id="проблемные-зоны-и-технологические-решения-в-автоматической-обработке-стандартных-и-нестандартных-речевых-данных" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="проблемные-зоны-и-технологические-решения-в-автоматической-обработке-стандартных-и-нестандартных-речевых-данных"><span class="header-section-number">7.2</span> Проблемные зоны и технологические решения в автоматической обработке стандартных и нестандартных речевых данных</h2>
<section id="диаризация-оценка-качества-на-материалах-корпуса-обработка-новых-данных-спонтанной-устной-речи-курс" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="диаризация-оценка-качества-на-материалах-корпуса-обработка-новых-данных-спонтанной-устной-речи-курс"><span class="header-section-number">7.2.1</span> Диаризация: оценка качества на материалах корпуса, обработка новых данных спонтанной устной речи КУРС</h3>
<p>В 2025 сотрудники лаборатории продолжили эксперименты по оценке возможностей и качества инструментов автоматической диаризации, т.е. процесса выделения говорящих в потоке речи. В дальнейшем модель и соответствующие утилиты становились частью общего цикла обработки звуковых данных корпуса. Анализ включал в себя сравнение распознанного текста, автоматически определенных временных меток и дикторов с данными транскрипций корпуса КУРС (Корпус устной речи студентов), полученными вручную экспертами. В эталонную выборку вошли 195 эпизодов, аудиозаписей с повседневной речью, собранных по методике «речевого дня». Записи сформированы как наборы аудиофайлов, охватывающие весь день информанта — от пробуждения до сна — либо отдельные разговоры.</p>
<p>Экспертная разметка эталонной выборки представляла собой таблицу, где каждой реплике соответствуют уникальный идентификатор говорящего, краткое описание эпизода, название аудиофайла, время начала и продолжительность речи. Текст реплик содержал маркеры синтагматического и фразового членения, а также обозначения пауз и паралингвистических явлений <span class="citation" data-cites="Bogdanova-Beglarian2016a">[<a href="13_references.html#ref-Bogdanova-Beglarian2016a" role="doc-biblioref">8</a>]</span>. Накладывающаяся речь записана в одну реплику, список одновременно говорящих разделен символом “@” или “#”. Тестовые автоматические данные в свою очередь включали в себя обозначение найденного говорящего, временную метку начала и окончания речи. Обозначение дикторов, формат таймкодов и пересечения реплик в речи отличают экспертную разметку от тестовой: в таблице от диаризатора идентификаторы говорящих повторяются для каждого из аудиофайлов, предлагаются временные метки начала и окончания фрагмента, одновременная речь разнесена по разным репликам с пересечением таймкодов.</p>
<p>Для тестирования качества форматы разметки были приведены к единому виду, чтобы устранить различия, не влияющие на смысловую нагрузку, но способные исказить метрики при сравнении гипотезы и референса. Так, была полностью удалена пунктуация, приведён регистр всех слов к нижнему, заменены «ё» на «е», числительные, как арабские, так и прописью, были заменены на маркер «числ». При этом при конвертации меток спикеров существовал риск ошибок, в результате которых диагностические параметры могли быть рассчитаны неверно. Сами пересечения реплик в экспертной разметке не подлежат преобразованию, т.к. извлечь таймкоды для отдельных говорящих в этом случае невозможно. Помимо прочего, встречаются редкие орфографические ошибки в эталонной разметке. Риски минимизировались дополнительными тестами для алгоритмов и ручной проверкой выровненных пар слов из экспертной и тестовой разметок.</p>
<p>Процесс обработки аудиоданных для тестирования состоял из четырех этапов: нормализации, диаризации и разделения аудио на фрагменты, распознавания и подсчета метрик. Вначале аудиофайлы были приведены к единому формату и необходимой для ASR частоте дискретизации, 16 кГц, была выровнена громкость. Далее проводилась диаризация аудио определение и сегментация фрагментов по говорящим. Полученные сегменты сохранялись в отдельные файлы и передавались модели распознавания. В конце по полученным расшифровкам подсчитывались диагностические параметры качества диаризации и распознавания.</p>
<p>В качестве метрик использовались стандартные параметры качества диаризации и распознанного текста <span class="citation" data-cites="Karpov2012">[<a href="13_references.html#ref-Karpov2012" role="doc-biblioref">9</a>]</span>: DER (Diarization Error Rate), DWER (Diarization Word Error Rate), SAWER (Speech Attributed Word Error Rate) и собственно WER (Word Error Rate). Все четыре основываются на подсчете количества замен, пропусков и добавлений слов, DWER дополнительно указывает, какой процент слов от общего количества слов был определен неверно, т.е. отнесен не к тому спикеру. SAWER — количество неправильно распознанных слов в речи каждого из говорящих.</p>
<p>Для распознавания речи взята модель ASR Whisper Large v3 (ранее замеры качества и сравнение с НТР проводилось в <span class="citation" data-cites="Sherstinova2024a">[<a href="13_references.html#ref-Sherstinova2024a" role="doc-biblioref">10</a>]</span>), для диаризации выбрана pyannote <span class="citation" data-cites="Bredin">[<a href="13_references.html#ref-Bredin" role="doc-biblioref">11</a>]</span>: фреймворк с открытым исходным кодом и модель, демонстрирующая DER 34,4 и 24 на данных датасетов DIHARD и ETAPE.</p>
<p>Результат: Результаты расчётов метрики DER по референсной и тестовой выборке показывают значительное варьирование качества диаризации. Минимальное значение DER составило 10,3, в то время как максимальные значения стремятся к 100. При этом для 10% аудиозаписей ошибка диаризации не превышает 27,9. Среднее значение DER по всей выборке оказалось также достаточно высоким — 68,3, при этом медиана составила 52,6. Наилучшие результаты и относительная стабильность алгоритма достигаются в аудиозаписях с простыми условиями: нет лишних шумов, количество говорящих не превышает одного-двух, речь громка и отчетлива.</p>
<p>Средние значения параметров WER, DWER и SAWER находятся в диапазоне 46,1 до 64, медиана — от 46,2 до 62,9. Менее чем у 10% аудиозаписей WER составляет 27,4, DWER — 24,0, SAWER — 30,6. 90-й процентиль достигает для WER 62,6, DWER — 81,1, SAWER — 96,8. Максимальные значения достигают 100. Несмотря на то что минимальные значения (от 8,4 до 13,3) говорят о наличии немногих высококачественных распознаваний, в целом система, как и при диаризации, демонстрирует заметное варьирование качества.</p>
<p>К настоящему моменту с помощью моделей диаризации и ASR обработано 869 макроэпизодов КУРС.</p>
</section>
<section id="автоматическое-распознавание-атипичной-речи-на-русском-языке-на-материале-речи-пациентов-с-афазией-разработка-бенчмарка" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="автоматическое-распознавание-атипичной-речи-на-русском-языке-на-материале-речи-пациентов-с-афазией-разработка-бенчмарка"><span class="header-section-number">7.2.2</span> Автоматическое распознавание атипичной речи на русском языке (на материале речи пациентов с афазией) : разработка бенчмарка</h3>
<p>Одной из задач проекта стало сравнение инклюзивности и оценка качества распознавания атипичной (афазической) речи у моделей автоматического распознавания речи (АРР), которые доступны на российском рынке.</p>
<p>В качества материала исследования выступил датасет RuAphasiaBank, собранный в отчетном году сотрудниками лаборатории. Датасет RuAphasiaBank представляет собой корпус речевых записей, собранный для исследования афазической речи. Записи были получены в Центре нейрореабилитации ФСНКЦ ФМБА России (г. Красноярск). Все пациенты (или их доверенные лица), включенные в исследование, подписывали информированное согласие на анонимизированную запись голоса. Для проведения исследования было получено официальное разрешение этического комитета НИУ ВШЭ. Запись осуществлялась во время занятий с логопедом в стационаре. Расстояние между пациентом и логопедом составляло около 50 см, а между пациентом и звукозаписывающим устройством не более 25 см. Использовались стандартные диктофоны, встроенные в телефоны марки iPhone. Для соблюдения принципов конфиденциальности во время записи устройства были в офлайн-режиме. После записи передавались исследовательской группе на физических носителях, где проходили процедуру анонимизации: каждая запись прослушивалась, и любая информация личного характера (ФИО, дата и место рождения, место проживания) исключалась из записи с помощью специальных инструментов обработки звука. Каждой записи присваивался уникальный идентификационный номер, который представляет собой сокращенное описание метаданных записи (номер фонограммы в рамках датасета, номер спикера в рамках датасета, пол, возраст, диагноз, степень тяжести).</p>
<p>Как можно заметить в <a href="#tbl-4" class="quarto-xref">таблица&nbsp;<span>7.4</span></a> датасет включает 188 аудиозаписей, из которых 164 относятся к атипичной речи, а 24 – к речи нейротипичных информантов. Всего в выборке представлено 70 пациентов с различными формами афазии и 20 нейротипичных спикеров. Временной объем датасета составляет 9,6 часов звучания, при этом средняя продолжительность речевого материала, приходящаяся на одного пациента, составляет около 0,14 часа.</p>
<div id="tbl-4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.4 – Основные характеристики датасета RuAphasiaBank
</figcaption>
<div aria-describedby="tbl-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Тип распределения/ Признак</th>
<th>По пациентам</th>
<th>По типу афазии</th>
<th>По степени нарушения</th>
<th>По типу речи</th>
<th>По типу текста</th>
<th>По нейротипичным информантам</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Общее количество</strong></td>
<td><em>Пациентов/ записей : 70 / 164</em></td>
<td><em>Пациентов/ записей :</em><br>КМА – 58/140<br>ЭфА – 2/6<br>Сем – 2/3<br>Сенс – 5/10<br>АМ – 1/1<br>Т – 2/4</td>
<td><em>Пациентов/ записей:</em><br>Легкая – 5/12<br>Средняя – 30/91<br>Тяжелая – 35/61</td>
<td><em>Записей:</em><br>Монолог – 19<br>Чтение – 27<br>Пересказ – 18<br>Слоги – 13</td>
<td>Записей :<br>Дидакт – 17<br>Худож – 29<br>Упрощ – 21</td>
<td><em>Информантов/ записей : 20/24</em></td>
</tr>
<tr class="even">
<td><strong>Гендер (М и Ж)</strong></td>
<td><em>Пациентов/ записей (кол-во):</em> <br>54/129 (М)<br>16/35 (Ж)</td>
<td><em>Пациентов M/Ж (кол-во):</em><br>КМА – 44/14<br>ЭфА – 2/0<br>Сем – 2/0<br>Сенс - 3/2<br>АМ – 1/0<br>Т – 2/0</td>
<td><em>Пациентов M/Ж (кол-во):</em><br>Легкая – 3/2<br>Средняя – 25/5<br>Тяжелая – 27/8</td>
<td><em>Записей (кол-во) M/Ж :</em><br>Диалог – 39/12<br>Монолог – 12/3<br>Чтение – 10/4<br>Пересказ – 8/3<br>Слоги – 11/0</td>
<td><em>Записей (кол-во) M/Ж:</em><br>Дидакт – 14/3<br>Худож – 21/8<br>Упрощ – 9/12</td>
<td><em>M/Ж (кол-во):</em> 16/4</td>
</tr>
<tr class="odd">
<td><em>Средний возраст пациентов/ информантов</em></td>
<td>53,4 М 61,3 Ж</td>
<td>КМА – 52,4<br>ЭфА – 49,5<br>Сем – 63<br>Сенс – 65,4<br>АМ – 62<br>Т – 48</td>
<td>Легкая – неизв.<br>Средняя – 51,4<br>Тяжелая – 57,7</td>
<td>Диалог – 56,5<br>Монолог – 50,8<br>Чтение – 46,2<br>Пересказ – 45,2<br>Слоги – 53,7</td>
<td>Дидакт – 45,8<br>Худож – 44,4<br>Упрощ – неизв.</td>
<td>58,5</td>
</tr>
<tr class="even">
<td><em>Терапевт</em></td>
<td>8</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="odd">
<td><em>Время звучания (в час)</em></td>
<td>Общее – 9,6 час<br>Среднее на 1 пациента 0,14 час</td>
<td>КМА – 8,3 час<br>ЭфА – 0,31 час<br>Сем – 0,15 час<br>Сенс – 0,77 час<br>АМ – 0,09 час<br>Т – 0,20 час</td>
<td>Легкая – 0,55 час<br>Средняя – 5,4 час<br>Тяжелая – 3,9 час</td>
<td>Диалог – 5,6 час<br>Монолог – 1 час<br>Чтение – 1,5 час<br>Пересказ – 0,85 час<br>Чтение слогов – 0,62 час</td>
<td>Дидакт – 0,86 час<br>Худож – 1,6 час<br>Упрощ – 1,3 час</td>
<td>4,3 час</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Примечание – Условные сокращения: КМА — комплексная моторная афазия, ЭфА — эфферентная афазия, Сем — семантическая афазия, сенс — сенсорная афазия, АМ — акустико-мнестическая афазия, Т — тотальная афазия (типология афазий дана по <span class="citation" data-cites="TSvetkova1988 Luriya1973 Luriya2008">[<a href="13_references.html#ref-TSvetkova1988" role="doc-biblioref">12</a>–<a href="13_references.html#ref-Luriya2008" role="doc-biblioref">14</a>]</span>; Дидакт — дидактические тексты, Худож — художественные тексты, Упрощ — упрощенные из датасета RuSimplAphasia.</p>
<p>В рамках данного исследования собранные данные использовались для проведения тестирования систем автоматического распознавания речи (АРР). Актуальность данного вопроса объясняется тем, что люди, страдающие афазией, остаются участниками речевой коммуникации с банками, медицинскими учреждениями, розничной торговлей и другими институциями, в повседневную жизнь которых уже вошли речевые технологии. Собранный датасет позволил оценить качество распознавания и инклюзивность движков АРР на русском языке, доступных как коммерческие сервисы от ведущих российских разработчиков. На собранных данных тестировались общедоступные демо-версии облачных сервисов АРР: Сервисы, оцененные в данном исследовании, включают: Yandex SpeechKit <span class="citation" data-cites="YandexSpeechKit">[<a href="13_references.html#ref-YandexSpeechKit" role="doc-biblioref">15</a>]</span>, SaluteSpeech <span class="citation" data-cites="SaluteSpeech">[<a href="13_references.html#ref-SaluteSpeech" role="doc-biblioref">16</a>]</span> (приложение для компьютера), Shopot <span class="citation" data-cites="ShopotAI">[<a href="13_references.html#ref-ShopotAI" role="doc-biblioref">17</a>]</span>, T-bank <span class="citation" data-cites="VoiceKit">[<a href="13_references.html#ref-VoiceKit" role="doc-biblioref">18</a>]</span>. Эти движки уже вошли в состав голосовых помощников, платформ для анализа речи и клиентского опыта и стали универсальными решениями преобразования звучащей речи в текст.</p>
<p>Для оценки качества работы систем АРР на собранных данных рассчитывалась WER (пословная ошибка распознавания) и CER (посимвольная ошибка распознавания). Для расчета метрик были вручную размечены эталонные тексты: 44 аудиозаписи пациентов 28-76 лет (31 мужчина и 8 женщин) с легкой и умеренной, преимущественно, комплексно-моторной афазией. Для разметки были отобраны три типа речи: монолог (11 записей), чтение вслух (17 записей) и пересказ (16 записей). В качестве контрольного подмножества данных вручную затранскрибировали 15 записей монологической речи 13 нейротипичных респондентов в возрасте 55-65 лет. Подробные расчеты WER и CER для каждой модели представлены в <a href="#tbl-5" class="quarto-xref">таблица&nbsp;<span>7.5</span></a>.</p>
<p>В ходе экспериментов была выявлена неоднородность качества работы систем автоматического распознавания речи (АРР) на контрольном подмножестве и на различных типах речи. Наибольшая точность при распознавании монологической речи была зафиксирована у сервиса Yandex SpeechKit (медиана WER = 0,16 – 0,55). В то же время, система SaluteSpeech показала на данном типе речи наименьшие результаты (медиана WER = 0,34 – 0,72). Следует отметить, что для сервисов Yandex SpeechKit и SaluteSpeech была характерна тенденция к двукратному повышению точности распознавания монологов респондентов с афазией по сравнению с речью нейротипичных респондентов. Системы Shopot и T-Bank продемонстрировали эквивалентное качество АРР для монологов пациентов и контрольной группы. При этом сервис T-Bank показал ухудшение метрик для речи пациентов с афазией по сравнению с нейротипичной речью, что указывает на его пониженную устойчивость к речевым нарушениям, характерным для данного нарушения.</p>
<p>Модель АРР Yandex SpeechKit демонстрирует наиболее стабильное качество распознавания на монологах и записях контрольной группы, что подтверждается относительно низкими и плотно кластеризованными значениями WER и CER. Вместе с тем, на фонограммах с чтением и пересказом пациентов с афазией наблюдается значительный рост количества ошибок распознавания и их высокая вариабельность. Наибольшие затруднения у модели вызывает задача на чтение: максимальные значения WER превышают 100%, а показатель CER характеризуется широким разбросом.</p>
<p>Модель АРР SaluteSpeech демонстрирует более высокую точность обработки монологической речи лиц с афазией по сравнению с нейротипичными респондентами. При выполнении задания на чтение модель показала значения WER, сопоставимые с контрольной группой, однако распределение ошибок в контрольной группе было значительно более плотным. Наибольшие трудности у системы вызвало подмножество пересказа, где медиана WER достигла 72%. Следует отметить, что значительно более низкий уровень посимвольной ошибки (CER) в речи лиц с афазией по сравнению с контрольной группой указывает на снижение качества работы модели при обработке спонтанной, быстрой и лексически разнообразной нейротипичной речи. Выраженное расхождение между WER и CER в записях пациентов с афазией свидетельствует о среднем качестве распознавания на фонемном уровне (низкий CER), но о нарушенном лексико-семантическом сопоставлении (высокий WER). В противоположность этому, сбалансированное соотношение WER ≈ CER в контрольных записях, вероятно, отражает влияние нелингвистических факторов и сложности, связанные с распознаванием относительно быстрой спонтанной речи.</p>
<p>Модель АРР Shopot демонстрирует относительно низкий уровень ошибок при распознавании монологов (медиана WER = 29%). При этом монологи пациентов с афазией (WER = 29 – 59%) распознаются с сопоставимой или более высокой точностью по сравнению с речью контрольной группы (WER = 31 – 88%), что может свидетельствовать о специфической адаптации модели к медленной речи. Результаты контрольной группы характеризуются большей стабильностью (WER: 31–41% до 90-го процентиля). Вместе с тем, модель Shopot показывает более низкое качество при распознавании пересказа (медиана WER = 36%) и чтения (медиана WER = 38%). Наибольшие трудности система испытывает в заданиях на пересказ, где точность распознавания ниже, чем в заданиях на чтение, что указывает на проблемы при обработке несвязной речи пациентов. Стабильно более низкие значения CER по сравнению с WER на всех наборах данных позволяют сделать вывод о том, что модель обеспечивает точное распознавание на фонемном уровне, однако испытывает значительные трудности на уровне лексико-семантической интерпретации.</p>
<p>Модель АРР T-Bank демонстрирует оптимальные результаты при обработке монологов (WER = 30–52%) и речи в контрольной группе (WER = 28–38%). Несмотря на сопоставимую базовую точность для обеих подгрупп, записи пациентов характеризуются значительно большим разбросом ошибок (до 52% против 38%). Следует отметить, что контрольная группа сохраняет исключительную стабильность как по показателям WER (28–38%), так и CER (15–23%). Наихудшие результаты система T-Bank показывает при распознавании чтения (WER = 52–105%) и пересказа (WER = 43–98%). Наиболее проблемным сценарием является чтение: значение WER достигает 105% на 99-м процентиле, что свидетельствует о неприспособленности модели к обработке речевых данных подобной сложности. При этом показатель CER остается относительно низким (25–59%). Полученные данные позволяют предположить, что основная проблема модели заключается в распознавании целых слов, а не в интерпретации на уровне фонем. Точность распознавания пересказа (медиана WER = 43%) является средней, превосходя результаты по чтению, но уступая показателям для монологов. В качестве итога представлены лучшие результаты по типам речи: в <a href="#tbl-5" class="quarto-xref">таблица&nbsp;<span>7.5</span></a> наименьшие проценты ошибок для каждой категории выделены жирным шрифтом.</p>
<div id="tbl-5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.5 – Метрики качества российских движков АРР, полученные на датасете RuAphasiaBank (% - процентиль)
</figcaption>
<div aria-describedby="tbl-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Движок АРР</th>
<th>Монолог (50/99%)</th>
<th>Чтение (50/99%)</th>
<th>Пересказ (50/99%)</th>
<th>Контрольная группа, монологи (50/99%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yandex SpeechKit</td>
<td>WER: 0.16/0.49<br><br>CER: 0.1/0.31</td>
<td>WER: 0.55/1.11<br><br>CER: 0.28/0.81</td>
<td>WER: 0.49/0.98<br><br>CER: 0.24/0.55</td>
<td>WER: 0.42/0.48<br><br>CER: 0.26/0.3</td>
</tr>
<tr class="even">
<td>SaluteSpeech</td>
<td>WER: 0.34/0.59<br><br>CER: 0.19/0.41</td>
<td>WER: 0.60/1.00<br><br>CER: 0.23/0.51</td>
<td>WER: 0.72/1.00<br><br>CER: 0.20/0.47</td>
<td>WER: 0.64/0.71<br><br>CER: 0.26/0.69</td>
</tr>
<tr class="odd">
<td>Shopot</td>
<td>WER: 0.29/0.59<br><br>CER: 0.19/0.53</td>
<td>WER: 0.38/0.80<br><br>CER: 0.2/0.81</td>
<td>WER: 0.36/0.88<br><br>CER: 0.22/0.58</td>
<td>WER: 0.31/0.88<br><br>CER: 0.18/0.74</td>
</tr>
<tr class="even">
<td>T-bank</td>
<td>WER: 0.30/0.52<br><br>CER: 0.15/0.31</td>
<td>WER: 0.52/1.05<br><br>CER: 0.25/0.59</td>
<td>WER: 0.43/0.98<br><br>CER: 0.26/0.74</td>
<td>WER: 0.28/0.38<br><br>CER: 0.15/0.23</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Анализ метрик, представленных в <a href="#tbl-5" class="quarto-xref">таблица&nbsp;<span>7.5</span></a>, позволяет выявить характерные особенности каждого движка АРР. Yandex SpeechKit демонстрирует наибольшую точность при обработке монологов пациентов с афазией. Модель Shopot показывает самый низкий уровень ошибок по метрике WER в наиболее сложных для распознавания сценариях — чтении и пересказе. В то же время SaluteSpeech лидирует в этих же сценариях по метрике CER, причем для записей пациентов с афазией у данной модели наблюдается выраженное расхождение между значениями WER и CER. T-Bank превосходит остальные системы в распознавании спонтанной разговорной речи нейротипичных информантов, а также в целом демонстрирует стабильное качество при обработке различных типов речи.</p>
<p>Все рассмотренные системы АРР демонстрируют значительное снижение качества распознавания в заданиях на чтение и пересказ, что подтверждается ростом показателя WER при стабильно низких значениях CER. Данная картина указывает на системные проблемы, связанные скорее с лексической интерпретацией, чем с ограничениями акустического распознавания. При обработке спонтанной речи проявляется общая закономерность: качество распознавания речи контрольной группы не всегда превышает результаты для атипичной речи пациентов с афазией. В частности, все системы АРР, за исключением T-Bank, показывают более высокий процент ошибок при распознавании речи в контрольной выборке, состоящей из записей монологов нейротипичных информантов, выполненных в идентичных технических условиях. Наблюдаемый тренд позволяет выдвинуть предположение о том, что современные системы АРР на российском рынке могут быть непреднамеренно переобучены на гиперартикулированной речи, что затрудняет корректную обработку естественной разговорной речи даже в отсутствие речевых патологий.</p>
<p>Собранный и размеченный датасет RuAphasiaBank является уникальным ресурсом, необходимым для мониторинга качества систем АРР для русского языка, поскольку в известном датасете AphasiaBank <span class="citation" data-cites="MacWhinney2015">[<a href="13_references.html#ref-MacWhinney2015" role="doc-biblioref">19</a>]</span> русский язык не представлен, а сущесвующие датасеты для русского языка меньше по объему и более специфичны по выборке <span class="citation" data-cites="Khudyakova2016">[<a href="13_references.html#ref-Khudyakova2016" role="doc-biblioref">20</a>]</span>. Его использование позволило оценить системы АРР при распознавании разных видов атипичной речи, а также естественной разговорной монологической речи пользователей возрастного диапазона 55 – 66 лет. В результате проведенного тестирования мы получили два, на наш взгляд, интересных наблюдения.</p>
<p>Во-первых, в записях пациентов с афазией такие виды речи, как пересказ и чтение, несмотря на свой репродуктивный, а не продуктивный характер, оказались более трудными для АРР, чем монолог. Это связано с тем, что большинство использованных записей чтения и пересказов принадлежит пациентам с комплексной моторной афазией, которые испытывают трудности с планированием высказывания на основе нового содержания, и с артикуляцией, у них затруднен выбор артикулем, переход от одной моторной программы к другой. В монологе те же пациенты часто прибегают к использованию автоматизированных речевых рядов (<em>первое, второе, третье и компот</em>), устойчивых речений (<em>дела как сажа бела</em>), клише (<em>меня зовут</em>) произнесение которых для пациента облегчено речевой привычкой.</p>
<p>Во-вторых, неожиданным оказалось то, что три из четырех протестированных систем показывают на атипичных монологах даже лучшие результаты, чем на типичной разговорной монологической речи информантов старше 50 лет. Данный факт связан, по-видимому, с тем, что в разговорной речи в естественных условиях у информантов наблюдается стремление к экономии речевых усилий, приводящее к разнообразным фонетическим редукциям и усечениям форм, и эта тенденция с возрастом усиливается. Модели же обучены, в основном, на речи дикторов, актеров, имеющих профессиональную привычку к четкой, даже утрированной, артикуляции. У пациентов с афазией как раз наблюдается стремление к утрированной артикуляции, хотя при этом, довольно часто, снижена сила голоса.</p>
<p>Следует отметить, что некоторые из рассмотренных систем дают для отдельных видов речи относительно высокие метрики качества, но при изменении типа речи их показатели резко ухудшаются. Иными словами, говорить об инклюзивности моделей, попавших в тестовую выборку, пока сложно даже применительно к речи нейротипичных пользователей.</p>
<p>В перспективе созданный датасет RuAphasiaBank позволит осуществлять регулярный мониторинг инструментов АРР, используемых в России коммерческими и государственными организациями, формируя репрезентативные бенчмарки для оценки качества распознавания афазической речи.</p>
<p>РИД: База данных «RuAphasiaBank, база данных фонограмм речи пациентов с афазией». Свидетельство о государственной регистрации базы данных: № 2025623465.</p>
<p>Вид РИД: база данных. Авторский коллектив:</p>
<ul>
<li>Колмогорова Анастасия Владимировна (заведующий Лабораторией языковой конвергенции);</li>
<li>Явшиц Екатерина Валерьевна (младший научный сотрудник);</li>
<li>Сугян Анна Хачатуровна (стажер-исследователь);</li>
<li>Сергеева Мария Олеговна (стажер-исследователь).</li>
</ul>
<p>База данных представляет собой структурированную коллекцию аудиозаписей речи и сопутствующих метаданных. Состав РИД включает:</p>
<ul>
<li>Набор аудиофайлов в формате .wav с записями речи;</li>
<li>Текстовый файл в формате .csv, содержащий подробные метаданные для каждого аудиофайла.</li>
</ul>
</section>
<section id="объектный-сентимент-анализ-отзывов-на-культурные-институции-с-помощью-больших-языковых-моделей-на-материале-датасета-отзывов-посетителей-владимиро-суздальского-музея-заповедника" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="объектный-сентимент-анализ-отзывов-на-культурные-институции-с-помощью-больших-языковых-моделей-на-материале-датасета-отзывов-посетителей-владимиро-суздальского-музея-заповедника"><span class="header-section-number">7.2.3</span> Объектный сентимент-анализ отзывов на культурные институции с помощью больших языковых моделей (на материале датасета отзывов посетителей Владимиро-суздальского музея-заповедника)</h3>
<p>В рамках проекта решалась задача проверки эффективности больших языковых моделей (LLM) как инструмента для аспектно-ориентированного анализа тональности (ABSA) в условиях отсутствия предопределенного набора целевых аспектов и присущей данным политематичности.</p>
<p>Впервые в качестве данных для сентимент-анализа выступили тексты отзывов на культурные институции. Традиционным объектом применения методов сентимент-анализа являются отзывы на товары и услуги, однако постепенно формируется относительно новый тип отзывов – отзывы посетителей учреждений науки и культуры. У подобных текстов существует своя специфика, в значительной мере отличающая их от других оценочных субжанров. В частности, подобные тексты совмещают в себе черты не только оценочных жанров, но и рефлексивов, нарративов о жизни и т.д.</p>
<p>Исследование было подчинено задачам, поставленным заказчиком – Владимиро-Суздальским музейным комплексом. Необходимо было собрать датасет отзывов с существующих цифровых платформ и автоматически выявить, что нравится, а что не нравится посетителям музейного комплекса. При этом требовалось сфокусироваться на динамике, т.е. сохранить тренды по годам (с 2020 по 2025).</p>
<p>В качестве материала исследования использовались 12,187 отзывов из 9 публично доступных онлайн-ресурсов на 15 объектов Владимиро-Суздальского музея-заповедника в период 2020-2025 гг. Отзывы были получены путем веб-скрейпинга (автоматического сбора текстовых данных из интернета). Характеристики корпуса отзывов указаны в <a href="#tbl-6" class="quarto-xref">таблица&nbsp;<span>7.6</span></a>.</p>
<div id="tbl-6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.6 – Распределение отзывов по категориям
</figcaption>
<div aria-describedby="tbl-6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Музейным объектам</th>
<th>N</th>
<th>По платформам-источникам</th>
<th>N</th>
<th>По годам</th>
<th>N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Суздальский Кремль</td>
<td>2527</td>
<td>Yandex Maps</td>
<td>6305</td>
<td>2020</td>
<td>2400</td>
</tr>
<tr class="even">
<td>Спасо-Евфимиев монастырь</td>
<td>2218</td>
<td>Google Maps</td>
<td>5090</td>
<td>2021</td>
<td>1643</td>
</tr>
<tr class="odd">
<td>Музей деревянного зодчества</td>
<td>1888</td>
<td>Tripadvisor</td>
<td>523</td>
<td>2022</td>
<td>2373</td>
</tr>
<tr class="even">
<td>Музей хрусталя</td>
<td>781</td>
<td>Otzovik</td>
<td>93</td>
<td>2023</td>
<td>2013</td>
</tr>
<tr class="odd">
<td>Успенский собор</td>
<td>690</td>
<td>2gis</td>
<td>85</td>
<td>2024</td>
<td>3467</td>
</tr>
<tr class="even">
<td>Музей Мальцовых</td>
<td>673</td>
<td>Fooby</td>
<td>40</td>
<td>2025</td>
<td>291</td>
</tr>
<tr class="odd">
<td>Исторический музей</td>
<td>663</td>
<td>Autotravel</td>
<td>25</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Димитриевский собор</td>
<td>620</td>
<td>Irecommend</td>
<td>23</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Палаты</td>
<td>505</td>
<td>Tonkosti</td>
<td>3</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Церковь Бориса и Глеба</td>
<td>583</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Золотые ворота</td>
<td>403</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Музей природы</td>
<td>344</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Дом-музей Столетовых</td>
<td>271</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Музей «Старый Владимир»</td>
<td>40</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Музей-усадьба В. Храповицкого</td>
<td>21</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Для выполнения задачи использовались следующие методы:</p>
<ol type="1">
<li>Веб-скрейпинг</li>
<li>Автоматическая предобработка данных (формирование таблиц, очистка от пустых отзывов, сортировка по годам)</li>
<li>Аспектно-ориентированный сентимент-анализ</li>
<li>Применение больших языковых моделей (запуск моделей через llama-cpp-python локально)</li>
<li>Стратегический промпт-инжиниринг</li>
</ol>
<p>Разработан пайплайн обработки отзывов для автоматического формирования отчетов по позитивным и негативным категориям объекта по годам. Пайплайн представлен в <a href="#fig-spb_2" class="quarto-xref">рисунок&nbsp;<span>7.2</span></a>. Модель вызывается 2 раза: сначала ей дается промт с инструкцией извлечь негативные и позитивные ключевые слова из отзывов по каждому объекту и по каждому году; затем модель получает инструкцию разделить все полученные на первом этапе ключевые слова на предзаданные обязательные и факультативные категории. Среди обязательных категорий: экспозиция, персонал, месторасположение, еда и туалеты, цены, внешний вид объектов и территории; среди факультативных: посещение с детьми, условия для людей с ограниченными физическими возможностями, эмоции и атмосфера, общее впечатление, знания и образование, развлечения и шоппинг, доступность (как добраться до места), история и патриотическое воспитание. Под ключевым словом в данной работе подразумевался минимальный фрагмент текста, имеющий предикацию – это могло быть адъективно субстантивное сочетание (<em>увлекательная экскурсия</em>), а могло быть простое предложение с глагольной группой (<em>учитель прошел бесплатно</em>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_2.jpg" class="img-fluid figure-img" width="1024">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.2 – Пайплайн обработки отзывов.
</figcaption>
</figure>
</div>
</div>
</div>
<p>В качестве используемой большой языковой модели была выбрана модель YandexGPT5-Lite-8B-instruct-Q8_0<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, показавшая наилучший результат для выбранной задачи. Характеристики модели представлены в <a href="#tbl-7" class="quarto-xref">таблица&nbsp;<span>7.7</span></a>.</p>
<div id="tbl-7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.7 – Параметры модели YandexGPT
</figcaption>
<div aria-describedby="tbl-7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Параметр</th>
<th>Значение</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Количество параметров</td>
<td>8 миллиардов</td>
</tr>
<tr class="even">
<td>Базовая архитектура</td>
<td>Llama</td>
</tr>
<tr class="odd">
<td>Квантизация</td>
<td>Q8_0 (8 bit) in GGUF format</td>
</tr>
<tr class="even">
<td>Размер модели</td>
<td>8.54 GB</td>
</tr>
<tr class="odd">
<td>Максимальный размер контекста</td>
<td>32K</td>
</tr>
<tr class="even">
<td>Совместимость</td>
<td>Совместима с llama.cpp</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>В результате обработки были сформированы 15 таблиц с позитивными и негативными ключевыми словами по каждому объекту, а также 15 текстовых отчетов, где ключевые слова были распределены по позитивным и негативным категориям с помощью большой языковой модели. Отчеты были проверены экспертно, количество галлюцинаций модели (неправильное отнесение к категориям, логические, синтаксические ошибки, несуществующие ключевые слова) составили не более 7% от общего числа ключевых слов. Пример итогового результата можно увидеть в <a href="#fig-spb_3" class="quarto-xref">рисунок&nbsp;<span>7.3</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_3.jpg" class="img-fluid figure-img" width="1024">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.3 – Пример текстового отчета по категориям.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Категориями с самым большим числом позитивных ключевых слов стали Экспозиция, Общее впечатление, Эмоции и атмосфера (<a href="#fig-spb_4" class="quarto-xref">рисунок&nbsp;<span>7.4</span></a>). Категориями с самым большим числом негативных ключевых слов: Экспозиция, Цены, Общее впечатление (<a href="#fig-spb_5" class="quarto-xref">рисунок&nbsp;<span>7.5</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_4.jpg" class="img-fluid figure-img" width="592">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.4 – Тематические категории с наибольшим числом позитивных ключевых слов.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_5.jpg" class="img-fluid figure-img" width="534">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.5 – Тематические категории с наибольшим числом негативных ключевых слов.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Результат: разработан и апробирован эффективный пайплайн для аспектного сентимент-анализа отзывов на культурные институции с помощью больших языковых моделей. Заказчику предоставлены данные в динамике по 15 объектам за требуемый период времени. На основании полученных данных ведется работа по описанию коллективного портрета современного посетителя музея.Разработанный метод может быть экстраполирован на другие культурные институции.</p>
<p><em>Данный результат достигнут в рамках соглашения о научном сотрудничестве между НИУ ВШЭ Санкт-Петербург и Федеральным государственным бюджетным учреждением культуры «Государственный Владимиро-Суздальский историко-архитектурный и художественный музей-заповедник» (подписан 20 января 2025 г.).</em></p>
</section>
<section id="конвергентные-речевые-практики-русскоязычного-сегмента-интернет-на-материале-корпусных-данных" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="конвергентные-речевые-практики-русскоязычного-сегмента-интернет-на-материале-корпусных-данных"><span class="header-section-number">7.2.4</span> Конвергентные речевые практики русскоязычного сегмента Интернет (на материале корпусных данных)</h3>
<p>Задача данной части проекта – исследование цифровыми методами распространенных речевых и дискурсивных практик, используемых носителями русского языка в социальных сетях русскоязычного сегмента сети Интернет. В фокусе работы в отчетном году - дискурсивные практики зообъявлений и гороскопов.</p>
<p>Согласно Дж. Берджеру, первой древний союз человека и животного пошатнула декартовская идея l’animal-machine, а окончательно он был разрушен в эпоху позднего капитализма <span class="citation" data-cites="Berger2017">[<a href="13_references.html#ref-Berger2017" role="doc-biblioref">21</a>]</span>. Нечеловеческие животные оказались вытеснены из центра человеческого опыта на периферию культуры: в книги, мультфильмы, иллюстрации, детские игрушки и зоопарки. Квартира так же, как и зоопарк, лишает животного автономии и ограничивает его естественные потребности. Домашнее животное служит антропоцентричным желаниям хозяина, наряду с умной бытовой техникой <span class="citation" data-cites="Krylova2023">[<a href="13_references.html#ref-Krylova2023" role="doc-biblioref">22</a>]</span>. Оно должно быть/стать милым, удобным, неприхотливым и полезным, даже если это противоречит его естественным потребностям.</p>
<p>Целью нашего исследования является выявление схем репрезентации «идеального» питомца на «рынках животных» в социальных сетях. С помощью корпусного анализа предпринимается попытка определить особенности речевого жанра «зообъявление», который, несмотря на свою распространенность, ранее не подвергался подобному количественному описанию.</p>
<p>В качестве материала используются тексты из групп «ВКонтакте», которые занимаются публикацией зоообъявлений, направленных на мотивацию подписчика принять некоторое животное «в добрые руки». Обращение к Интернет-сообществам именно помощи животным обуславливается стремление проследить лексические особенности, которые подобные тексты, несмотря на их бытование в функционально немаркетинговом информационном поле, наследуют из рекламного дискурса <span class="citation" data-cites="Markowitz2020">[<a href="13_references.html#ref-Markowitz2020" role="doc-biblioref">23</a>]</span>. Кроме того, интерес представляют дискурсивные паттерны, которые используются при представлении животных разных видов для потенциальных хозяев. В соответствии с этой задачей были собраны посты из двух групп: одна специализируется на публикации объявлений о котах/кошках, вторая — о собаках. Объем каждого из корпусов составил 22291 пост (2301189 словоупотреблений) и 22783 поста (2255550 словоупотреблений) соответственно.</p>
<p>Частотный, коллокационный и анализ эмоций позволили выделить устойчивые схемы репрезентации животных, использующиеся в зоообъявлениях для создания привлекательного образа потенциального питомца.</p>
<p>Наиболее характерной для конструирования образа как кошки, так и собаки оказывается лексико-тематическая группа «принятие в дом/семью» (<em>дом</em>, <em>человек</em>, <em>искать</em>, <em>семья</em>, <em>хозяин</em>). Однако отметим, что частотной в cat_c оказывается лемма «<em>дом</em>» (9838<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, ср. dog_c: 8168), в то время как в dog_c обнаруживается высокое ранговое положение другой леммы — «<em>семья</em>» (dog_c: 5807, cat_c: 3504). На обнаруживаемое речевое выражение ментального стереотипа «собака — друг человека» указывает также и то, что лемма «<em>компаньон</em>» используется при описании собаки практически в два раза чаще (532), чем при описании кота/кошки (275).</p>
<p>В объявлениях о собаках также оказывается важным указание на породу собаки (например, <em>хаски</em> — 2122, <em>овчарка</em> — 1660, <em>метис</em> — 1283). В этом проявляется внимание некоторых людей к вопросу «чистоты» породы: породистые собаки находятся выше в иерархии, чем метисы и беспородные.</p>
<p>Кошка же, по всей видимости, рассматривается как атрибут домашнего уюта, подчеркивается ее домашность (лемма «<em>домашний</em>» в cat_c и dog_c соответственно: 1647 vs.&nbsp;780) и ласковость (лемма «<em>ласковый</em>» в cat_c и dog_c соответственно: 4869 vs.&nbsp;2360). Кроме того, кошек чаще, чем собак, именуют «<em>малыш</em>» (cat_c: 1799 vs.&nbsp;dog_c: 738), «<em>малышка</em>» (1494 vs.&nbsp;524). В отличие от собаки, образ кошки в данном дискурсе отличается меньшей автономностью.</p>
<p>Тема чистоты является актуальной для реализации образа как собаки, так и кошки, однако частотно значимый разрыв обнаруживается именно для последних (ср., лемма «<em>паразит</em>» встречается в cat_c и в dog_c соответственно: 1212 и 557). Вероятно, это связано с преимущественно «indoors» условиями содержания котов, в отличие от собак. Активное и даже неизбежное взаимодействие собак с внешней средой смягчает требования к их гигиене (см. <a href="#fig-spb_6" class="quarto-xref">рисунок&nbsp;<span>7.6</span></a> и <a href="#fig-spb_7" class="quarto-xref">рисунок&nbsp;<span>7.7</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_6.jpg" class="img-fluid figure-img" width="1024">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.6 – Коллокаты леммы «кошка»
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_7.jpg" class="img-fluid figure-img" width="1024">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.7 – Коллокаты леммы «собака»
</figcaption>
</figure>
</div>
</div>
</div>
<p>Обратимся к результатам автоматического детектирования эмоций, для которого использовалась модель rubert-tiny2-russian-emotion-detection<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Так, в корпусах выделяются эвокативные структуры, характеризуемые следующими эмоциями: <em>любовь</em> (cat_c: 43,35%<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, dog_c: 32,84%), <em>печаль</em> (cat_c: 10,21%, dog_c: 10,11%), <em>восхищение</em> (cat_c: 9,86%, dog_c: 12,49%), <em>любопытство</em> (cat_c: 4,45%, dog_c: 3,9%), <em>благодарность</em> (cat_c: 3,88%, dog_c: 2,1%), <em>забота</em> (cat_c: 2,91%, dog_c: 6,19%), <em>радость</em> (cat_c: 1,88%, dog_c: 2,93%), <em>одобрение</em> (cat_c: 0,1%, dog_c: 1,42%).</p>
<p>Наиболее выраженной оказалась эмоция <em>любовь</em> (cat_c: 43,35%<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, dog_c: 32,84%): так, в текстах конструируется эмоциональное состояние, которое должна вызывать ситуация адопции животного. Интересно, что эмоция <em>восхищение</em> в большей мере ассоциирована с зоообъявлениями о собаках (cat_c: 9,86%, dog_c: 12,49%). Действительно, в этих постах выделяются характеристики животного, которые призваны восхитить потенциального хозяина, в первую очередь связанные со спортивными достижениями породистых собак (<em>имеет первые медали</em>) или чертами внешности (<em>яркий красавец</em>, <em>классный</em>, <em>просто шикарный</em>).</p>
<p>Астрологический прогноз — другой особый жанр, получивший широкое распространение в медийном пространстве постсоветской действительности Такие особенности гороскопического текста, как функциональная направленность, рекомендательный характер, а также специфика выражения модальности и оценки, вызывают лингвистический интерес и описываются в ряде исследований <span class="citation" data-cites="Aznacheeva2011 Vepreva2017">[<a href="13_references.html#ref-Aznacheeva2011" role="doc-biblioref">24</a>; <a href="13_references.html#ref-Vepreva2017" role="doc-biblioref">25</a>]</span>. Неслучайно характерные признаки названных текстов изучаются и как черты медиажанров <span class="citation" data-cites="Laletina2007">[<a href="13_references.html#ref-Laletina2007" role="doc-biblioref">26</a>]</span>: гороскопы встречаются в журналах, газетах, распространяются по радио, публикуются на форумах в сети Интернет.</p>
<p>Цель следующего этапа исследования — проследить особенности лексического состава текстов, в том числе проверить, проявляются ли архетипические черты в астрологических прогнозах и представляют ли гороскопы отдельный речевой жанр. Под гороскопами будут пониматься ежедневные предсказания, то есть тексты, которые предписывают то или иное поведение или пророчат некоторые события в определенный день согласно знаку зодиака человека.</p>
<p>Материалом исследования выступили гороскопы, размещенные в открытых группах «ВКонтакте», которые занимаются регулярной публикацией ежедневных астрологических прогнозов для каждого из 12 знаков зодиака с 2014 по 2025 гг. (включительно). Пример выгрузки, за исключением некоторых не используемых в рамках этого исследования метаданных (количество лайков, комментариев, репостов, просмотров, оставленных пользователями), представлен в <a href="#tbl-8" class="quarto-xref">таблица&nbsp;<span>7.8</span></a>. В «сыром» виде полученный датасет насчитывал 90642 строки (около 17 тыс. строк на каждый знак зодиака). Далее осуществлялась очистка данных в несколько этапов. Так, были удалены тексты, не являющиеся гороскопами вида «ежедневное предсказание»: рекламные и поздравительные посты, гороскопы на неделю, год и иные временные промежутки, а также гороскопы, составленные не в соответствии с зодиакальной системой (например, кельтские гороскопы). Затем автоматически были «развернуты» посты, которые в одном тексте включали несколько видов, — общий, бизнес- и любовный гороскопы.</p>
<div id="tbl-8" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.8 – Пример выгрузки (фрагмент датасета)
</figcaption>
<div aria-describedby="tbl-8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>ID</th>
<th>Заголовок</th>
<th>Текст</th>
<th>Год публикации</th>
<th>Знак зодиака</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1436</td>
<td>Любовный гороскоп на 16 марта 2025 года</td>
<td>Спокойствие, только спокойствие - так проще достичь желаемого!</td>
<td>2025</td>
<td>Стрелец</td>
</tr>
<tr class="even">
<td>4911</td>
<td>Гороскоп на 30 мая 2024 года</td>
<td>Нынче у вас должна обостриться интуиция. Ей и следуйте.</td>
<td>2024</td>
<td>Лев</td>
</tr>
<tr class="odd">
<td>31540</td>
<td>Гороскоп на 25 апреля 2018</td>
<td>Наиболее трудные дела пока отложите.</td>
<td>2018</td>
<td>Рак</td>
</tr>
<tr class="even">
<td>33931</td>
<td>Бизнес-гороскоп на 01 октября 2017</td>
<td>Будьте осторожны в финансовых делах. Возможны происки неожиданных конкурентов.</td>
<td>2017</td>
<td>Телец</td>
</tr>
<tr class="odd">
<td>46142</td>
<td>Общий гороскоп на завтра, 9 сентября, 2016</td>
<td>Вы прекрасный исполнитель и способны многого добиться. Сегодня Вам предстоит работать с общественностью.</td>
<td>2016</td>
<td>Козерог</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>После удаления «мусорных» постов и гороскопов-дублей (без учета знака зодиака), токенизации и лемматизации, выполненных с помощью MyStem<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, а также сегментации на предложения с использованием библиотеки NLTK <span class="citation" data-cites="Bird2009">[<a href="13_references.html#ref-Bird2009" role="doc-biblioref">27</a>]</span>, объем корпуса составил 28149 строк или 1185425 словоупотреблений (15578 лексических типов). Средний размер группы гороскопов, приходящихся на каждый знак зодиака, равен 2346 текстам со средним суммарным объемом 99427,42 токена. Текст гороскопа как единица анализа имеет следующее лингвостатистическое описание (в средних значениях): длина в словах — 42,39 (σ — 13,97), длина в предложениях — 3,42 (σ — 1,18).</p>
<p>В исследовании используются частотный, коллокационный и сентимент-анализ.</p>
<p>Рассмотрим лексические особенности гороскопических текстов. На примере наиболее релевантных сочетаний слов прослеживаются прагматико-дискурсивные черты подобного текста: предсказание событий на завтра (<em>день</em>, <em>завтра</em>), ориентация на положительный исход дня (<em>благоприятный</em>, <em>день</em>), а также межличностные отношения и рекомендации по их организации, в частности через открытость к новым встречам и знакомствам (<em>человек</em>, <em>новый</em>, <em>знакомство</em>, <em>отношение</em>).</p>
<p>Далее обратимся к <a href="#fig-spb_8" class="quarto-xref">рисунок&nbsp;<span>7.8</span></a>, на котором для каждой «зодиакальной» выборки визуализированы по 50 наиболее частотных содержательных и не входящих во множество общих для всего корпуса лексем.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_8" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_8.jpg" class="img-fluid figure-img" width="732">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.8 – Облака частотных слов для каждого подкорпуса (исключая стоп-слова и общие для всего корпуса)
</figcaption>
</figure>
</div>
</div>
</div>
<p>Например, в облаке слов, характеризующем Овна заметен фокус на карьеру (<em>шеф</em>, <em>торговля</em>, <em>совещание</em>) и советы «заботиться» (возможно, из-за стереотипов недостатка созидательности у представителей этого знака зодиака). Значительное место занимает лексика, связанная со знаниями, их получением и применением (<em>образование</em>, <em>изучение</em>, <em>философский</em>). В отношении Тельца заметна «предостерегающая» лексика (<em>угроза</em>, <em>агрессивный</em>), а также связанная с работой — примечательно, что появляется фигура подчиненного (<em>работник</em>, <em>офис</em>, <em>совещание</em>), а также материальный аспект (<em>вложение</em>). Вновь появляется указание на сферу взаимоотношений (<em>привязанность</em>, <em>заботиться</em>). Тема работы наблюдается и в частотных распределениях гороскопов, адресованных Козерогу (<em>перегрузка</em>, <em>масштаб</em>, <em>нервничать</em>), что согласуется с образом «трудяги», через который часто описывается этот знак. Для Льва тоже отмечается лексика, связанная с работой (<em>шеф</em>, <em>офис</em>, <em>специалист</em>), однако еще и с указанием на такие, действительно, приписываемые ему черты, как успешность в карьере и лидерские качества (<em>победитель</em>, <em>руководить</em>).</p>
<p>Несмотря на отмечаемые в некоторых случаях различия, проведенный анализ указывает на необходимость обращения к гороскопу как к единому дискурсивному полю, отличающемуся слабо выраженной дистинктивностью (по крайней мере, если в качестве дифференцирующего параметра рассматривать знак зодиака). В связи с этим мы провели еще один эксперимент, а именно сравнили частотные распределения лемм в пользовательском корпусе, описанном в этом исследовании (и условно названном «гороскопы в соцсетях»), и в подкорпусе гороскопов Национального корпуса русского языка (НКРЯ)<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Подкорпус «гороскопы» НКРЯ насчитывает 130 текстов суммарным объемом 105877 словоупотреблений. Как позволяют судить метаданные, гороскопы, включенные в НКРЯ, были составлены в период с 1991 по 2010 гг. (включительно) и представляют собой принципиально другой вид медиа. Так, их источниками выступают журналы, газеты, а также, что немаловажно, встречаются авторские астрологические прогнозы.</p>
<p>В результате сравнения верхней зоны частотных словарей стала заметна ориентированность гороскопов, публикуемых в социальных сетях, на прогнозирование событий завтрашнего дня, в то время как гороскопы в журналах и газетах, что несколько ожидаемо, охватывали конкретный <em>день</em> или <em>неделю</em> целиком. Объяснение находится в особенностях сферы функционирования этих текстов, а также в исключении из нашего корпуса не ежедневных предсказаний. Кроме того, кажется, что предсказания из соцсетей стремятся быть более личными, отсутствие чего в подкорпусе гороскопов из НКРЯ, вероятно, является метой ограничений, накладываемых на периодические издания, их внешней модерируемостью.</p>
<p>В обоих корпусах заметна тема рабочих отношений. Однако в подкорпусе НКРЯ лемма <em>работа</em> имеет ранг 24, а в корпусе «гороскопов в соцсетях» — 50. Похожая тенденция на «опущение» по рангу заметна и для некоторых других лексем: <em>здоровье</em> — 31 vs.&nbsp;234, <em>любовь</em> — 34 vs.&nbsp;87, <em>деньги</em> — 37 vs.&nbsp;289. По всей видимости, для ежедневных онлайн-предсказаний, хоть и важна, но в меньшей мере свойственна привязка к какому-либо конкретному аспекту жизни, в результате чего они представляются более общими и несколько абстрактными. В то время как для публикуемых в официальных СМИ гороскопах характерна выраженная категоризация «по сфере действия». Следующим шагом этой работы стало выявление особенностей эмоционального воздействия гороскопических текстов, определяемых на лексическом уровне. Для этого с использованием русскоязычного словаря оценочной лексики RuSentiLex <span class="citation" data-cites="Lukashevich2016">[<a href="13_references.html#ref-Lukashevich2016" role="doc-biblioref">28</a>]</span> и программного обеспечения Orange<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> был проведен анализ тональности. Расчет оценки тональности в настоящем исследовании производился в соответствии с <span class="citation" data-cites="Hu2004 Kolmogorova2024">[<a href="13_references.html#ref-Hu2004" role="doc-biblioref">29</a>; <a href="13_references.html#ref-Kolmogorova2024" role="doc-biblioref">30</a>]</span> по следующей формуле:</p>
<p><span class="math display">\[(sum(pos) - sum(neg)) / document\_length * 100 \]</span></p>
<p>,</p>
<p>гдe pos — количество положительных слов (в типах), neg — количество отрицательных слов (в типах), а document_length — длина документа (количество слов в тексте).</p>
<p>В результате были получены следующие распределения по количеству текстов: положительные — 12093 (42,96%), нейтральные — 10788 (38,32%), негативные — 5268 (18,71%), что согласуется с заключениями, представленными в <span class="citation" data-cites="Ling2016">[<a href="13_references.html#ref-Ling2016" role="doc-biblioref">31</a>]</span>. Так, и в нашем случае, кажется, что лексико-эмоциональное наполнение текстов имеет целью вызвать у читателя положительные эмоции: спокойствие, надежду, стабильность. Это гарантируется чтением предсказания, что функционально выступает действием эквивалентным возможности контролировать свое будущее. При этом, как видно исходя из <a href="#fig-spb_8" class="quarto-xref">рисунок&nbsp;<span>7.8</span></a>, знак зодиака не влияет на эмоциональную направленность текста, что вновь свидетельствует о генерализованном характере астрологических предсказаний.</p>
<p>Приведем несколько примеров положительных (1-2), негативных (3) и нейтральных предсказаний (4-5):</p>
<ol type="1">
<li><em>Сегодня вы одержите пусть небольшую, но победу. Этот день принесет вам уважение окружающих.</em></li>
<li><em>Сегодня вы просто обречены на успех в амурных делах. Не играйте в карты!</em></li>
<li><em>Сегодня вы рискуете допустить ошибку или в чем-то просчитаться. Вам могут предоставить недостоверную информацию, так что будьте бдительны.</em></li>
<li><em>Сегодня лучше действовать сообща. Одному столько не выпить.</em></li>
<li><em>На работе не будет происходить ничего особенного. Будете выполнять рутинные обязанности и мелкие поручения.</em></li>
</ol>
<p>Интересным показалось посмотреть, какое выражение принимает эмоциональная компонента в зависимости от цели текста: гороскопы общего характера превалируют (58,01%), затем следуют любовные гороскопы (32,01%) и бизнес-гороскопы (9,98%). Положительная лексическая тональность главным образом характерна для прогнозов в сфере любви. Обратившись к долям постов, сгруппированных по гороскопическим поджанрам и классам тональности, удалось подтвердить это наблюдение: так, 46,77% любовных гороскопов и 42,22% общего характера вне зависимости от знака зодиака имеют положительную «заряженность». Наиболее негативными, составляя 21,58% постов своей подгруппы, в свою очередь являются бизнес-гороскопы (вероятно, так проявляется свойственный гороскопам этого поджанра мотив <em>предостережения о неприятностях на работе</em>), а наименее — вновь любовные (доля отрицательных постов внутри этой категории — 16,54%).</p>
<p>Частотный анализ позволяет проследить некоторую лексику, тематически соответствующую архетипическим образам знаков зодиака, однако из-за высокой генерализованности предсказаний (наблюдается значительное количество повторений) и слабых различий между тематическими группами этот анализ скорее говорит о том, что гороскопы имеет смысл рассматривать как некоторый речевой жанр, но с мало выраженной внутренней различимостью, по крайней мере по параметру адресата, выраженного представителем определенного знака зодиака. Представляется, что гороскоп в современном медиаполе функционирует как «аффирмирующее послание», на что указывает также и превалирующая положительная тональность этих текстов, но не как персонализированная рекомендация.</p>
</section>
</section>
<section id="внедрение-результатов-исследовательской-работы-по-изучению-цифровыми-методами-конвергентных-процессов-в-современной-русской-речевой-практике" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="внедрение-результатов-исследовательской-работы-по-изучению-цифровыми-методами-конвергентных-процессов-в-современной-русской-речевой-практике"><span class="header-section-number">7.3</span> Внедрение результатов исследовательской работы по изучению цифровыми методами конвергентных процессов в современной русской речевой практике</h2>
<section id="лингвистические-цифровые-ресурсы-и-прикладные-разработки" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="лингвистические-цифровые-ресурсы-и-прикладные-разработки"><span class="header-section-number">7.3.1</span> Лингвистические цифровые ресурсы и прикладные разработки</h3>
<section id="модернизация-и-совершенствование-системы-векторного-поиска-картин-по-пользовательскому-описанию" class="level4" data-number="7.3.1.1">
<h4 data-number="7.3.1.1" class="anchored" data-anchor-id="модернизация-и-совершенствование-системы-векторного-поиска-картин-по-пользовательскому-описанию"><span class="header-section-number">7.3.1.1</span> Модернизация и совершенствование системы векторного поиска картин по пользовательскому описанию</h4>
<p>В рамках разработки поисковой функции для выбора картин Эрмитажа через чат-бот в 2025 г. был модернизирован существующий конвейер обработки запросов. Объем коллекции картин, доступных для поиска в боте, оставлен неизменным, 2000 картин; основное внимание было уделено улучшению качества и предсказуемости работы самой поисковой подсистемы при сохранении или снижении нагрузки на вычислительные ресурсы.</p>
<p>Первоначально функция поиска имела микросервисную архитектуру и опиралась на несколько сервисов Yandex Cloud (Yandex.Embeddings, Yandex.OpenSearch) . В ходе модернизации архитектура была упрощена: поисковая логика была целиком перенесена в технологию виртуального ассистента, Yandex AI Assistant, реализующего подход Retrieval-Augmented Generation (RAG) через sdk подключение, <a href="#fig-spb_9" class="quarto-xref">рисунок&nbsp;<span>7.9</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spb_9" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spb_9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/spb_conlab_9.jpg" class="img-fluid figure-img" width="640">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spb_9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Рисунок&nbsp;7.9 – Текущая архитектура поисковой функции
</figcaption>
</figure>
</div>
</div>
</div>
<p>В качестве базы знаний ассистента использованы текстовые описания картин и их метаданные, собранные с сайта «Цифровая коллекция Эрмитажа». Каждый документ был проиндексирован и получил уникальный идентификатор, используемый на этапе поиска и сопоставления с пользовательским запросом.</p>
<p>Каждая пользовательская сессия (тред, threads) в виртуальном ассистенте хранит историю запросов, промежуточные результаты поиска и рассуждения модели. Это позволяет оперативно отслеживать ошибки и аномалии в работе бота. Ранее для этих целей использовалась отдельная база данных для логирования действий пользователя, однако такой подход сопровождался задержками обновления и усложнял диагностику. Переход к механизму тредов обеспечил практически мгновенное обновление истории взаимодействий.</p>
<p>Дополнительно, благодаря сохранению контекста диалога в треде, поисковая функция получила возможность учитывать предыдущие реплики пользователя. Это позволяет уточнять исходный запрос, опираться на уже найденные результаты и использовать диалоговый контекст для более точного подбора картин.</p>
<p>Внесенные изменения позволили существенно снизить нагрузку на вычислительные ресурсы без ухудшения пользовательского опыта. Для команды разработки стала доступна удобная инфраструктура для анализа промежуточных результатов работы модели и оперативного реагирования на возможные ошибки.</p>
<p>Кроме того, расширение поиска за счёт учёта контекста диалога создает предпосылки для дальнейшего повышения релевантности выдачи и улучшения восприятия системы пользователями.</p>
</section>
<section id="динамика-роста-корпуса-русского-рассказа" class="level4" data-number="7.3.1.2">
<h4 data-number="7.3.1.2" class="anchored" data-anchor-id="динамика-роста-корпуса-русского-рассказа"><span class="header-section-number">7.3.1.2</span> Динамика роста корпуса русского рассказа</h4>
<p>Корпус русского рассказа XX века — филологический цифровой ресурс, разрабатываемый на базе Корпуса русского рассказа 1900-1930 гг., целью создания которого является популяризация и изучение русской малой прозы. Корпус включает репрезентативную коллекцию аннотированных текстов и охватывает творчество широкого круга писателей XX века — от классиков до малоизвестных авторов. В 2025 году основная работа по корпусу состояла в завершении вычитки и корректуры 1000 текстов представительной выборки 1006 писателей, творивших на протяжении столетия. Также проводилась доразметка по всем принятым в корпусе принципам аннотации Корпуса-240 для последующей публикации результатов. Наконец, была начата инвентаризация всего корпуса с целью систематизаиции материалов.</p>
<p>В 2025 году велась работа над завершением оцифровки, вычитки и корректуры электронных версий рассказов 1000 авторов, творивших на протяжении всего XX века. Составленный в прошлом году представительный список 1000 русских произаиков снова претерпел изменения, поскольку выяснилось, что 12 текстов не соответствовали жанру рассказа, описывали дореволюционные события, были написаны в эмиграции, адресованы детской аудитории, что противоречит принципам составления корпуса <span class="citation" data-cites="Martynenko2018 Martynenko2018a">[<a href="13_references.html#ref-Martynenko2018" role="doc-biblioref">32</a>; <a href="13_references.html#ref-Martynenko2018a" role="doc-biblioref">33</a>]</span>. После изменений список насчитывает 1006 персоналий (887 мужчин и 119 женщин), так как 6 рассказов написано в соавторстве <span class="citation" data-cites="Sherstinova2025">[<a href="13_references.html#ref-Sherstinova2025" role="doc-biblioref">34</a>]</span>. На данный момент выборка полностью откорректирована и готова к проведению исследований на ее материале.</p>
<p>Данная коллекция текстов представляет собой аннотированную часть корпуса, которая тщательно отбирается и вручную размечается для проведения исследований языка и стиля русской малой прозы. Создание экспертно аннотированного подкорпуса является ключевым моментом разработки ресурса, так как именно эти данные становятся потом обучающей выборкой для исследования больших объемов литературных произведений. Всего в корпусе принято 5 уровней аннотации:</p>
<ul>
<li>экспертная (ручная) тематическая разметка рассказов с опорой на расширенный набор тегов, впервые предложенный в <span class="citation" data-cites="Skrebtsova2020">[<a href="13_references.html#ref-Skrebtsova2020" role="doc-biblioref">35</a>]</span>;</li>
<li>оценка эмоционального влияния текстов на читателей, для чего используется метод, описанный ранее в <span class="citation" data-cites="Sherstinova2023b">[<a href="13_references.html#ref-Sherstinova2023b" role="doc-biblioref">36</a>]</span>: после прочтения текста респонденты должны оценить его с двух точек зрения: указать свое общее впечатление по десятибалльной шкале и определить, какие базовые по <span class="citation" data-cites="Ekman1999">[<a href="13_references.html#ref-Ekman1999" role="doc-biblioref">37</a>]</span> эмоции (радость, печаль, отвращение, удивление, гнев, страх) и в какой степени вызвало у них чтение этого рассказа (по шкале от 0 до 2);</li>
<li>разведение текстов на речь автора и речь персонажей с использованием инструмента для извлечения прямой речи, апробированного в <span class="citation" data-cites="Kirina2024">[<a href="13_references.html#ref-Kirina2024" role="doc-biblioref">38</a>]</span>. Наряду с этим выделяется и собственно информация о «говорящих» героях русского рассказа: составляются их «социобиографические профили», включающие в себя полное имя, информацию является ли герой главным в рассказе или нет, его роль в произведении, профессию, семейное положение, характеристику от автора, пол, возраст, социальное происхождение и пр. <span class="citation" data-cites="Sherstinova2023a">[<a href="13_references.html#ref-Sherstinova2023a" role="doc-biblioref">39</a>]</span>;</li>
<li>разметка эмоциональной лексики в соответствии с 11 эмоциями (страх, грусть, злоба, отвращение, стыд, счастье, наслаждение, веселье, удивление, гордость, облегчение) по методике, описанной в <span class="citation" data-cites="Moskvina2025">[<a href="13_references.html#ref-Moskvina2025" role="doc-biblioref">40</a>]</span>;</li>
<li>выделение диегетического звука в тексте <span class="citation" data-cites="Delazari2023">[<a href="13_references.html#ref-Delazari2023" role="doc-biblioref">41</a>]</span>.</li>
</ul>
<p>В 2025 году было протеггировано тематически 109 текстов, благодаря чему завершилась задача тематической разметки рассказов, входящих в Корпус-1000. Для тех же 109 рассказов были заполнены таблицы с оценкой силы вызываемых у читателя эмоций, однако точное количество этих таблиц уточняется. Помимо разметки литературного материала, продолжался поиск биографической информации о писателях, включенных в список 1006 персоналий, по методике, описанной в <span class="citation" data-cites="Sherstinova2019a">[<a href="13_references.html#ref-Sherstinova2019a" role="doc-biblioref">42</a>]</span>. В 2025 году были заполнены таблицы с биографическими данными для 124 писателей, рассказы которых включены в Корпус-1000.</p>
<p>Количественные показатели прироста корпуса вынесены в <a href="#tbl-9" class="quarto-xref">таблица&nbsp;<span>7.9</span></a>.</p>
<div id="tbl-9" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.9 – Динамика роста Корпуса русского рассказа XX века в 2024-2025 гг.
</figcaption>
<div aria-describedby="tbl-9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Кол-во рассказов/таблиц</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>2024</td>
<td>2025</td>
</tr>
<tr class="even">
<td>—</td>
<td>—</td>
<td>—</td>
</tr>
<tr class="odd">
<td>Вычитка, корректура</td>
<td>90</td>
<td>109</td>
</tr>
<tr class="even">
<td>Тематическое теггирование</td>
<td>90</td>
<td>109</td>
</tr>
<tr class="odd">
<td>Оценка эмоционального влияния</td>
<td>90</td>
<td>109</td>
</tr>
<tr class="even">
<td>Биографические данные</td>
<td>17</td>
<td>124</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Для демонстрации принципов разметки литературного материала, использующихся в корпусе, было принято решение провести полное аннотирование Корпуса-240 с последующей публикацией результатов. Данный подкорпус уже размечен по 4 из 5 уровней, описанных выше, поэтому для обозначенной цели выбран именно он, а не Корпус-1000.</p>
<p>Корпус-240, включащий 240 рассказов 1901–2000 гг. (по 2-3 рассказа на каждый год) общим объемом 531725 словоупотреблений, был предназначен для апробации экспериментальных уровней аннотирования — на уровне эмоций и диегетического звука <span class="citation" data-cites="Moskvina2025">[<a href="13_references.html#ref-Moskvina2025" role="doc-biblioref">40</a>]</span>. В 2025 году выполнялось разведение текстов подкорпуса на речь автора и речь персонажа. На данный момент сегментирован 161 рассказ из 240. Также были выделены говорящие персонажи, заполнены таблицы с их социобиографической информацией.</p>
<p>Таким образом, в 2025 году работа над Корпусом русского рассказа XX века достигла значимых результатов: была завершена вычитка и корректура аннотированной части корпуса, начата систематизация его материалов, а также доразметка текстов для демонстрации принципов аннотации.</p>
<p>РИД : База данных «Биографический датасет русских прозаиков XX века» (на этапе регистрации). Вид РИД: база данных.</p>
<p>Авторский коллектив:</p>
<ul>
<li>Шерстинова Т.Ю. (доцент департамента филологии НИУ ВШЭ – Санкт-Петербург); Урих А.Е. (студент).</li>
</ul>
<p>Общее описание и состав:</p>
<ul>
<li>База данных представляет собой структурированный биографический датасет, выполненный в формате .xlsx. Датасет содержит унифицированные биографии 650 русских прозаиков XX века.</li>
</ul>
<p>Объем и структура данных:</p>
<ul>
<li>Объем: 650 записей (биографий);</li>
<li>Структура: 30 столбцов с детализированным описанием жизни и творчества авторов.</li>
</ul>
</section>
<section id="динамика-развития-корпуса-устной-речи-студентов" class="level4" data-number="7.3.1.3">
<h4 data-number="7.3.1.3" class="anchored" data-anchor-id="динамика-развития-корпуса-устной-речи-студентов"><span class="header-section-number">7.3.1.3</span> Динамика развития Корпуса устной речи студентов</h4>
<p>Корпус устной речи молодёжи и студентов (КУРС) — проект, «направленный на создание мультимедийного языкового ресурса, предназначенного для изучения русского языка повседневного общения на материале живой неподготовленной устной речи, которую мы используем в бытовой и профессиональной коммуникации» <span class="citation" data-cites="Sherstinova2023c Sherstinova2024">[<a href="13_references.html#ref-Sherstinova2023c" role="doc-biblioref">43</a>; <a href="13_references.html#ref-Sherstinova2024" role="doc-biblioref">44</a>]</span>. Он основан на методике непрерывной записи речи, разработанной для корпуса «Один речевой день» (ОРД), запись которого велась с 2007 по 2016 год <span class="citation" data-cites="Asinovsky2009 Sherstinova2009 Bogdanova-Beglarian2016 Bogdanova-Beglarian2019">[<a href="13_references.html#ref-Asinovsky2009" role="doc-biblioref">45</a>–<a href="13_references.html#ref-Bogdanova-Beglarian2019" role="doc-biblioref">48</a>]</span>.</p>
<p>Для проекта по созданию КУРС основополагающей задачей остается увеличение объёма корпуса. Добровольцы, принимающие участие в записи корпуса, проживают свой обычный день с диктофоном, фиксируя речь в естественной среде. Информантам предоставляется возможность записывать как на профессиональный диктофон (Zoom H1n или Tascam DR-05X), так и на диктофон, встроенный в собственный мобильный телефон. Чаще всего информанты выбирают запись на профессиональную технику.</p>
<p>За период с начала 2025 года объём аудиозаписей в корпусе увеличился на 29%, получено 562 часа исходного материала. В настоящий момент общий объём корпуса достигает 1823 часов. Количество информантов увеличилось на 38%: 57 человека, из которых 34 женщины и 23 мужчины. За 2025 год прирост информантов-мужчин максимальный, 68%, однако по-прежнему гендерная выборка остаётся недостаточно сбалансированной.</p>
<p>Предполагается, что один речевой день — это 12-14 часов исходного материала, то есть период с утра до вечера. Собранные за прошедший год данные насчитывают 12 речевых дней (записи длительностью от 8 часов, сделанные без пауз в рамках одного дня), 11 неполных речевых дней (к ним были отнесены как записи, сделанные в рамках одного дня, но с паузами между записями, так и записи длительностью от 5 до 8 часов).</p>
<p>В среднем каждый из 57 новых информантов предоставляет 10 часов аудио. Суммарная продолжительность записей, полученных от одного человека, варьируется. Так, максимальное количество полученных за 2025 год от новых информантов часов звукозаписей составляет 30 часов, а минимальная длительность равна 1 часу. За всё время сбора КУРС максимальное число часов, записанное одним информантом, составило 134 часа, а минимум равнялся 20 минутам.</p>
<p>Помимо аудиофайлов речи информантов и их коммуникантов, в распоряжении КУРС имеется социологическая информация об участниках, которую они добровольно предоставляют, заполняя анкету для участия в исследовании. Так, средний возраст новых информантов составляет 21 год. В большинстве случаев их родной язык — русский. Также среди новых информантов были носители молдавского и персидского, до этого не представленных среди информантов. 41% новых информантов являются студентами НИУ ВШЭ преимущественно гуманитарных специальностей. Тем не менее, за 2025 год корпус пополнился записями речи представителей других профессиональных сфер: информационные технологии, история, экономика, медицина и другие.</p>
<p>На втором этапе работы с Корпусом устной речи молодёжи и студентов из полученных от информантов звуковых файлов извлекается важная информация — речь. Для этого файлы сегментируются на макроэпизоды, «крупные эпизоды, объединённые местом коммуникации, её условиями и участниками» <span class="citation" data-cites="Sherstinova2013">[<a href="13_references.html#ref-Sherstinova2013" role="doc-biblioref">49</a>]</span>, продолжительностью 20-40 минут, из которых удаляются неречевые фрагменты.</p>
<p>Каждый из эпизодов описывается в соответствии с методикой формального описания макроэпизодов, разработанной для ОРД. Она включает в себя аннотирование по типу, условию, месту коммуникации, а также указание социальных ролей информантов и коммуникантов. Работа по сегментации исходных звуковых файлов и описанию макроэпизодов выполняется вручную, после чего они передаются для автоматической расшифровки. За отчетный период были обработаны записи от 29 информантов: из 196 часов исходного материала получено 147 часов речи, 284 новых эпизода.</p>
<p>Следующим этапом является расшифровка аудиоматериала в текст с использованием стека технологий Whisper v3 (ASR) для автоматического распознавания речи и pyannote для диаризации (деления спикеров). После проводится ручная проверка и вычитка текстов. Использование акустической модели значительно ускоряет работу по обработке материала, тем не менее остаётся значительное число существенных ошибок, что требует ручной экспертной проверки. В <a href="#tbl-10" class="quarto-xref">таблица&nbsp;<span>7.10</span></a> приведены количественные результаты работы по увеличению объёма корпуса за 2025 год.</p>
<div id="tbl-10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.10 – Прирост Корпуса устной речи молодёжи и студентов за 2025 год
</figcaption>
<div aria-describedby="tbl-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 49%">
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 18%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>2022-2024</th>
<th>2025</th>
<th>прирост 2025</th>
<th>итог</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>количество информантов</td>
<td>94</td>
<td>57</td>
<td>38%</td>
<td>151</td>
</tr>
<tr class="even">
<td>женщины</td>
<td>83</td>
<td>34</td>
<td>29%</td>
<td>117</td>
</tr>
<tr class="odd">
<td>мужчины</td>
<td>11</td>
<td>23</td>
<td>68%</td>
<td>34</td>
</tr>
<tr class="even">
<td>количество исходно записанных часов</td>
<td>1261</td>
<td>562</td>
<td>31%</td>
<td>1823</td>
</tr>
<tr class="odd">
<td>количество сегментированных часов</td>
<td>548</td>
<td>196</td>
<td>26%</td>
<td>744</td>
</tr>
<tr class="even">
<td>объём чистой речи</td>
<td>380</td>
<td>147</td>
<td>28%</td>
<td>527</td>
</tr>
<tr class="odd">
<td>количество макроэпизодов</td>
<td>952</td>
<td>284</td>
<td>23%</td>
<td>1236</td>
</tr>
<tr class="even">
<td>количество иформантов</td>
<td>44</td>
<td>29</td>
<td>40%</td>
<td>73</td>
</tr>
<tr class="odd">
<td>количество расшифрованных часов</td>
<td>84</td>
<td>46</td>
<td>35%</td>
<td>130</td>
</tr>
<tr class="even">
<td>количество эпизодов</td>
<td>258</td>
<td>93</td>
<td>26%</td>
<td>351</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Одним из практических результатов работы над проектом по созданию Корпуса устной речи молодёжи и студентов является публикация материалов корпуса в открытом доступе. Для этой цели был создан сайт <a href="http://esc-corpus.ru/">esc-corpus.ru</a>, работающий в тестовом режиме. В 2025 году был увеличен объём данных, доступных в демо-версии корпуса, в <a href="#tbl-11" class="quarto-xref">таблица&nbsp;<span>7.11</span></a> отражены ключевые аспекты этого процесса.</p>
<div id="tbl-11" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Таблица&nbsp;7.11 – Динамика наполнения сайта КУРС
</figcaption>
<div aria-describedby="tbl-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>2024</th>
<th>2025</th>
<th>процент от общего количества</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>количество информантов</td>
<td>12</td>
<td>16</td>
<td>19%</td>
</tr>
<tr class="even">
<td>женщины</td>
<td>11</td>
<td>9</td>
<td>17%</td>
</tr>
<tr class="odd">
<td>мужчины</td>
<td>1</td>
<td>7</td>
<td>24%</td>
</tr>
<tr class="even">
<td>возрастная группа: 18-24</td>
<td>11</td>
<td>15</td>
<td>19%</td>
</tr>
<tr class="odd">
<td>возрастная группа: 25-35</td>
<td>0</td>
<td>1</td>
<td>13%</td>
</tr>
<tr class="even">
<td>возрастная группа: 36-54</td>
<td>1</td>
<td>0</td>
<td>33%</td>
</tr>
<tr class="odd">
<td>возрастная группа: 55+</td>
<td>0</td>
<td>0</td>
<td>0%</td>
</tr>
<tr class="even">
<td>количество токенов</td>
<td>55000</td>
<td>200000</td>
<td>н/д</td>
</tr>
<tr class="odd">
<td>количество часов речи</td>
<td>13</td>
<td>40</td>
<td>41%</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Кратный прирост корпуса затруднителен, так как значительное число записей представляет собой частные разговоры информантов, требующие экспертного внимания. Для предотвращения разглашения персональных данных материалы КУРС проходят обязательную процедуру анонимизации. Также в соответствии с Федеральным Законом от 05.04.2013 № 34-ФЗ (ред. от 01.07.2021) «О внесении изменений в статью 4 Закона Российской Федерации «О средствах массовой информации» и статью 13.21 Кодекса Российской Федерации об административных правонарушениях», в котором говорится о запрете публикации ненормативной лексики в печати и онлайн, в текстах расшифровок устной речи кодируется непечатная лексика (часть буквенных символов, входящих в состав четырёх корней, которые признаны нецензурными, заменены на символ «*»).</p>
<p>Анонимизация осуществляется по утверждённой методике и включает замену всей личной информации. Имена и фамилии, являясь важной частью бытовой коммуникации, заменяются на вымышленные аналоги. Ключевой принцип — сохранение ритмической структуры и количества слогов оригинала (например, «Саша» → «Маша%», «Сонечка» → «Тонечка%»). Адреса, номера телефонов, места работы/учёбы, названия организаций, которые прямо или косвенно могут идентифицировать говорящего, заменяются на обобщающие категории в угловых скобках (&lt;адрес&gt;, &lt;компания&gt;, &lt;номер&gt;).</p>
<p>В целом результаты 2025 года показывают устойчивую положительную динамику развития корпуса: рост объёма аудиоматериала, расширение круга информантов, появление новых языковых и социокультурных групп, а также внедрение автоматизированных технологий обработки данных. Полученные данные представляют уникальный материал, отражающий живую русскую речь XXI века, и формирующие базу для ее междисциплинарных исследований.</p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Kolmogorova2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Kolmogorova&nbsp;A. V., Nalobina&nbsp;P. A. Conceptualizing the space: How natural and artificial cognitive agents use topological semantics schemes (based on descriptions of paintings from the hermitage collection) // Epistemology and Philosophy of Science. —&nbsp;2025. —&nbsp;Vol.&nbsp;62, no.&nbsp;1. —&nbsp;P.&nbsp;170–197.</div>
</div>
<div id="ref-Lin2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Lin&nbsp;C.&nbsp;Z. <a href="https://arXiv:2306.01879">Revisiting the role of language priors in vision-language models</a>. —&nbsp;2024.</div>
</div>
<div id="ref-Subbiah2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Subbiah M.&nbsp;C. L. B.&nbsp;Zhang S. Reading subtext: Evaluating large language models on short story summarization with writers // Transactions of the Association for Computational Linguistics. —&nbsp;Cambridge, MA: MIT Press, 2024. —&nbsp;Vol.&nbsp;12. —&nbsp;P.&nbsp;1290–1310.</div>
</div>
<div id="ref-SHmid2003" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Шмид&nbsp;В. Нарратология. —&nbsp;Москва: Яз. славян. культуры : Кошелев, 2003. —&nbsp;С.&nbsp;311.</div>
</div>
<div id="ref-Lin2004" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Lin&nbsp;C.-Y. <a href="https://aclanthology.org/W04-1013/"><span>ROUGE</span>: A package for automatic evaluation of summaries</a> / Text summarization branches out. —&nbsp;Barcelona, Spain: Association for Computational Linguistics, 2004. —&nbsp;P.&nbsp;74–81.</div>
</div>
<div id="ref-Papineni2002" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">al.&nbsp;P. et. <a href="https://aclanthology.org/P02-1040/"><span>B</span>leu: A method for automatic evaluation of machine translation</a> / Proceedings of the 40th annual meeting of the association for computational linguistics / ed. by Isabelle P.&nbsp;L. D.&nbsp;Charniak E. —&nbsp;Philadelphia, Pennsylvania, USA: Association for Computational Linguistics, 2002. —&nbsp;P.&nbsp;311–318.</div>
</div>
<div id="ref-Zhang2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><a href="https://api.semanticscholar.org/CorpusID:127986044">Zhang&nbsp;T., Kishore&nbsp;V., Wu&nbsp;F., Weinberger&nbsp;K. Q., Artzi&nbsp;Y. // ArXiv. —&nbsp;2019. —&nbsp;Vol.&nbsp;abs/1904.09675</a>.</div>
</div>
<div id="ref-Bogdanova-Beglarian2016a" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Богданова-Бегларян&nbsp;Ш.&nbsp;Н. В. Русский язык повседневного общения: Особенности функционирования в разных социальных группах. —&nbsp;Санкт-Петербург: ЛАЙКА, 2016. —&nbsp;С.&nbsp;244.</div>
</div>
<div id="ref-Karpov2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Карпов&nbsp;К.&nbsp;А. А. Методология оценивания работы систем автоматического распознавания речи // Известия высших учебных заведений. Приборостроение. —&nbsp;2012. —&nbsp;Т.&nbsp;55, №&nbsp;11. —&nbsp;С.&nbsp;38–43.</div>
</div>
<div id="ref-Sherstinova2024a" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Sherstinova&nbsp;M.&nbsp;T. Bridging gaps in russian language processing: AI and everyday conversations / 35th conference of open innovations association (FRUCT). —&nbsp;2024. —&nbsp;P.&nbsp;253–258.</div>
</div>
<div id="ref-Bredin" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">al.&nbsp;H. B. et. <a href="https://arxiv.org/abs/1911.01255">Pyannote.audio: Neural building blocks for speaker diarization</a>.</div>
</div>
<div id="ref-TSvetkova1988" class="csl-entry" role="listitem">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Цветкова&nbsp;Л. С. Афазия и восстановительное обучение. —&nbsp;Москва: Просвещение, 1988. —&nbsp;С.&nbsp;207.</div>
</div>
<div id="ref-Luriya1973" class="csl-entry" role="listitem">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Лурия&nbsp;А. Р. Основы нейропсихологии. —&nbsp;Москва: Изд-во Моск. ун-та, 1973. —&nbsp;С.&nbsp;374.</div>
</div>
<div id="ref-Luriya2008" class="csl-entry" role="listitem">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Лурия&nbsp;А. Р. Высшие корковые функции человека. —&nbsp;Санкт-Петербург: Питер, 2008. —&nbsp;С.&nbsp;431.</div>
</div>
<div id="ref-YandexSpeechKit" class="csl-entry" role="listitem">
<div class="csl-left-margin">15. </div><div class="csl-right-inline"><a href="https://cloud.yandex.ru/services/speechkit">Yandex SpeechKit</a>.</div>
</div>
<div id="ref-SaluteSpeech" class="csl-entry" role="listitem">
<div class="csl-left-margin">16. </div><div class="csl-right-inline"><a href="https://developers.sber.ru/portal/products/smartspeech">SaluteSpeech</a>.</div>
</div>
<div id="ref-ShopotAI" class="csl-entry" role="listitem">
<div class="csl-left-margin">17. </div><div class="csl-right-inline"><a href="https://shopot.ai/">Schöpot.ai</a>.</div>
</div>
<div id="ref-VoiceKit" class="csl-entry" role="listitem">
<div class="csl-left-margin">18. </div><div class="csl-right-inline"><a href="https://www.tbank.ru/software/voicekit/">VoiceKit</a>.</div>
</div>
<div id="ref-MacWhinney2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">MacWhinney&nbsp;B. <a href="https://doi:10.3389/conf.fpsyg.2015.65.00055">Analyses of AphasiaBank data</a>. —&nbsp;2015.</div>
</div>
<div id="ref-Khudyakova2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Khudyakova&nbsp;B.&nbsp;M. Russian CliPS: A corpus of narratives by brain-damaged individuals / RaPID-2016. —&nbsp;Saarbruecken, 2016. —&nbsp;P.&nbsp;22–26.</div>
</div>
<div id="ref-Berger2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Берджер&nbsp;Д. Зачем смотреть на животных? —&nbsp;Москва: Ад Маргинем Пресс, 2017. —&nbsp;С.&nbsp;160.</div>
</div>
<div id="ref-Krylova2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Крылова&nbsp;К. Рынок удобных животных. —&nbsp;Москва: НЛО, 2023. —&nbsp;С.&nbsp;408.</div>
</div>
<div id="ref-Markowitz2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Markowitz&nbsp;D. M. Putting your best pet forward: Language patterns of persuasion in online pet advertisements // Journal of Applied Social Psychology. —&nbsp;2020. —&nbsp;Vol.&nbsp;50, no.&nbsp;3. —&nbsp;P.&nbsp;160–173.</div>
</div>
<div id="ref-Aznacheeva2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Азначеева&nbsp;Е. Н. Астрологический дискурс: Семиотический и когнитивный аспекты // Вестник Челябинского государственного университета. —&nbsp;2011. —&nbsp;Вып.&nbsp;33. —&nbsp;С.&nbsp;19–21.</div>
</div>
<div id="ref-Vepreva2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Вепрева&nbsp;И. Т. Базовый лексикон астрологического прогноза: О словах с "размытым" содержанием // Экология языка и коммуникативная практика. —&nbsp;2017. —&nbsp;Вып.&nbsp;1. —&nbsp;С.&nbsp;57–63.</div>
</div>
<div id="ref-Laletina2007" class="csl-entry" role="listitem">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Лалетина&nbsp;А. О. Гороскоп как гендерно-маркированный медиажанр // Жанры и типы текста в научном и медийном дискурсе. —&nbsp;2007. —&nbsp;С.&nbsp;288–294.</div>
</div>
<div id="ref-Bird2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Bird&nbsp;K.&nbsp;S. <a href="https://www.nltk.org/book">Natural language processing with python</a>. —&nbsp;O’Reilly Media Inc., 2009.</div>
</div>
<div id="ref-Lukashevich2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Лукашевич&nbsp;Л.&nbsp;Н. В. Создание лексикона оценочных слов русского языка РуСентилекс // Труды конференции OSTIS-2016. —&nbsp;2016. —&nbsp;С.&nbsp;377–382.</div>
</div>
<div id="ref-Hu2004" class="csl-entry" role="listitem">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Hu&nbsp;M., Liu&nbsp;B. Mining opinion features in customer reviews / Proceedings of AAAI conference on artificial intelligence. —&nbsp;2004. —&nbsp;Vol.&nbsp;4. —&nbsp;P.&nbsp;755–760.</div>
</div>
<div id="ref-Kolmogorova2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Колмогорова&nbsp;К.&nbsp;А. В. <a href="https://DOI:10.17223/19986645/89/4">О прошлом, но в разное время: Компьютерный анализ текстов учебников по истории СССР / россии для шести поколений студентов</a> // Вестник Томского государственного университета. Филология. —&nbsp;2024. —&nbsp;Вып.&nbsp;89. —&nbsp;С.&nbsp;73–103.</div>
</div>
<div id="ref-Ling2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Ling&nbsp;Y. S. C. The use of modal auxiliary verbs in horoscope: A corpus-based study // Issues in Language Studies. —&nbsp;2016. —&nbsp;Vol.&nbsp;5, no.&nbsp;2.</div>
</div>
<div id="ref-Martynenko2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Мартыненко&nbsp;Ш.&nbsp;Г. Я. Методологические проблемы создания компьютерной антологии русского рассказа как языкового ресурса для исследования языка и стиля русской художественной прозы в эпоху революционных перемен (первой трети XX века). —&nbsp;2018. —&nbsp;Вып.&nbsp;2. —&nbsp;С.&nbsp;97–102.</div>
</div>
<div id="ref-Martynenko2018a" class="csl-entry" role="listitem">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Мартыненко&nbsp;Ш.&nbsp;Г. Я. О принципах создания корпуса русского рассказа первой трети XX века // Труды XV международной конференции по компьютерной и когнитивной лингвистике «TEL 2018». —&nbsp;2018. —&nbsp;С.&nbsp;180–197.</div>
</div>
<div id="ref-Sherstinova2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Шерстинова&nbsp;К.&nbsp;Т. Ю. Корпус русского рассказа XX века: Текущее состояние и перспективы развития. —&nbsp;2025.</div>
</div>
<div id="ref-Skrebtsova2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Skrebtsova&nbsp;T. Thematic tagging of literary fiction: The case of early 20th century russian short stories / CEUR workshop proceedings: Proceedings of the international conference "internet and modern society" (IMS-2020). —&nbsp;2020. —&nbsp;Vol.&nbsp;2813. —&nbsp;P.&nbsp;265–276.</div>
</div>
<div id="ref-Sherstinova2023b" class="csl-entry" role="listitem">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Шерстинова&nbsp;К.&nbsp;Т. Ю. Русский рассказ 1900-1930-х и его восприятие читателем: Опыт квантитативного анализа оценки художественного текста. —&nbsp;2023. —&nbsp;Вып.&nbsp;2 (54). —&nbsp;С.&nbsp;164–184.</div>
</div>
<div id="ref-Ekman1999" class="csl-entry" role="listitem">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Ekman&nbsp;P. Facial expressions. —&nbsp;Chichester: Wiley, 1999. —&nbsp;P.&nbsp;301–320.</div>
</div>
<div id="ref-Kirina2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Кирина&nbsp;Л.&nbsp;М. А. Голос эпохи: Лингвостатистические показатели прямой речи в русском рассказе XX века // Восьмая калининградская школа по гуманитарной информатике. Сборник докладов. Калининград, 12–14 декабря 2024 года. —&nbsp;2024. —&nbsp;С.&nbsp;69–73.</div>
</div>
<div id="ref-Sherstinova2023a" class="csl-entry" role="listitem">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Шерстинова&nbsp;К.&nbsp;Т. Ю. Корпус русского рассказа как база для проведения социолингвистических исследований русской литературы // Информационные технологии в гуманитарных исследованиях: Материалы международной научно-практической конференции, красноярск, 25–28 сентября 2023 г. —&nbsp;2023. —&nbsp;С.&nbsp;200–211.</div>
</div>
<div id="ref-Moskvina2025" class="csl-entry" role="listitem">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">Moskvina&nbsp;K.&nbsp;A. Fear and loathing in russian literature: A case of emotion annotation of short stories of the 20th century / International conference on internet and modern society. —&nbsp;2025. —&nbsp;P.&nbsp;113–129.</div>
</div>
<div id="ref-Delazari2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Делазари&nbsp;И. Комиксы на слух: Диегетический звук как трансмедиальная категория. —&nbsp;2023. —&nbsp;Т.&nbsp;179, №&nbsp;1. —&nbsp;С.&nbsp;118–132.</div>
</div>
<div id="ref-Sherstinova2019a" class="csl-entry" role="listitem">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Шерстинова&nbsp;Т. Ю. Биографическая база данных русских писателей (к созданию корпуса русского рассказа XX века) // Корпусная лингвистика-2019. —&nbsp;2019. —&nbsp;С.&nbsp;439–447.</div>
</div>
<div id="ref-Sherstinova2023c" class="csl-entry" role="listitem">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Шерстинова&nbsp;П.&nbsp;Т. Ю. Моделирование повседневного речевого поведения: Корпус устной речи молодежи, или ОРД v. 2.0. —&nbsp;2023. —&nbsp;Вып.&nbsp;11.</div>
</div>
<div id="ref-Sherstinova2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Sherstinova&nbsp;P.&nbsp;T. ESC corpus of spoken russian: Everyday student conversations captured through continuous speech recording in natural communicative environments / 26th international conference on speech and computer SPECOM-2024, 25-28 november 2024, belgrade, serbia. —&nbsp;2024.</div>
</div>
<div id="ref-Asinovsky2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Asinovsky&nbsp;A. et al. The ORD speech corpus of russian everyday communication "one speaker’s day": Creation principles and annotation / Text, speech and dialogue: 12th international conference (TSD 2009). —&nbsp;2009. —&nbsp;P.&nbsp;250–257.</div>
</div>
<div id="ref-Sherstinova2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Sherstinova&nbsp;T. The structure of the ORD speech corpus of russian everyday communication / International conference on text, speech and dialogue. —&nbsp;2009. —&nbsp;P.&nbsp;258–265.</div>
</div>
<div id="ref-Bogdanova-Beglarian2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">47. </div><div class="csl-right-inline">Bogdanova-Beglarian&nbsp;N. et al. Sociolinguistic extension of the ORD corpus of russian everyday speech / Speech and computer: 18th international conference (SPECOM 2016), 23 - 27 august 2016, budapest, hungary. —&nbsp;2016. —&nbsp;P.&nbsp;659–666.</div>
</div>
<div id="ref-Bogdanova-Beglarian2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">48. </div><div class="csl-right-inline">Богданова-Бегларян&nbsp;Н. В. и. др. Корпус русского языка повседневного общения «один речевой день» (ОРД): Текущее состояние и перспективы. —&nbsp;2019. —&nbsp;Т.&nbsp;21. —&nbsp;С.&nbsp;100–110.</div>
</div>
<div id="ref-Sherstinova2013" class="csl-entry" role="listitem">
<div class="csl-left-margin">49. </div><div class="csl-right-inline">Шерстинова&nbsp;Т. Ю. Коммуникативные макроэпизоды в корпусе повседневной русской речи "один речевой день": Принципы аннотирования и результаты статистической обработки // Корпусная лингвистика-2013: Тр. Междунар. конф. —&nbsp;2013. —&nbsp;С.&nbsp;449–456.</div>
</div>
</div>
</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Являясь партнером Лаборатории языковой конвергенции, Яндекс предоставил сотрудникам подразделения бесплатный доступ к модели.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://huggingface.co/BoloniniD/YandexGPT-5-Lite-8B-instruct-Q8_0-GGUF" class="uri">https://huggingface.co/BoloniniD/YandexGPT-5-Lite-8B-instruct-Q8_0-GGUF</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Здесь и далее частотность в корпусе указывается в IPM (item per million) с округлением до целых.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://huggingface.co/seara/rubert-tiny2-russian-emotion-detection-ru-go-emotions" class="uri">https://huggingface.co/seara/rubert-tiny2-russian-emotion-detection-ru-go-emotions</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Указывается процент постов, которые были классифицированы как соответствующая эмоция.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Указывается процент постов, которые были классифицированы как соответствующая эмоция.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>MyStem 3.1 = морфологический парсер [Электронный ресурс] // Yandex. URL: https://yandex.ru/dev/mystem (дата обращения: 15.06.2025).<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Национальный корпус русского языка [Электронный ресурс]. URL: https://ruscorpora.ru/stats (дата обращения 01.07.2025).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Orange3 Text Mining = software [Electronic resource] // Laboratory of Bioinformatics, Faculty of Computer Science, University of Ljubljana. URL: https://orangedatamining.com (date of access: 01.07.2025).<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./06_chapter.html" class="pagination-link" aria-label="Исследование и сравнительный анализ вариативности обозначения причинно-следственных связей в текстах обучающихся и экспертов, языковых особенностей и возможности орфокоррекции учебных текстов">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Исследование и сравнительный анализ вариативности обозначения причинно-следственных связей в текстах обучающихся и экспертов, языковых особенностей и возможности орфокоррекции учебных текстов</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./13_references.html" class="pagination-link" aria-label="СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ">
        <span class="nav-page-text">СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>